\thispagestyle{fancy2}

画像の時系列データを入力として，オンライン処理で複数の物体を追跡する問題は，複数物体追跡（Multi-Object Tracking; MOT）と呼ばれ，\cite{luo2021multiple}，防犯カメラに映る歩行者や自動車の追跡など，広く利用されている．しかしながらこれらの手法のほとんどは，一時刻に画像が一枚入力される３次元データにしか対応していない．特に，本問題設定のように３次元の空間情報が複数のスライス画像で与えられる４次元データにそのまま適用できる手法は未だ開発されていない．
\par
よってこの章では，新たに本問題設定のような問題に適用できるような手法を提案する．また提案手法の基盤として，一般的な複数物体追跡問題にしばしば利用されるYOLO+SORT\cite{redmon2016you,alif2024yolov1,bewley2016simple}を説明する．

\section{既存手法と問題点}
既存手法が対象にしている問題設定では，前述の通り一時刻の入力が画像一枚である．またYOLO+SORTでは，物体の情報をBounding-Boxと呼ばれる矩形情報$\left[x, y, w, h\right]$で表現する．ここで$(x,y)$は画像における物体の位置，$w$は物体の幅，$h$は物体の高さである．よって推定される物体の状態変数$\bm{s}_t$は，このBounding-Boxの持つ変数及びそれらの時間微分で与えられる．
\par
以上の議論から，既存手法が対象にしている問題における，時刻$t$の入力データ$\mathcal{X}_t$は，

\begin{equation}
    \mathcal{X}_t \in \mathbb{R}^{W \times H \times 3}
\end{equation}
で表せられ，物体の状態変数$\bm{s}_t$は，

\begin{equation}
    \label{eq:sort_state}
    \bm{s}_t \equiv \left[x_t, \dot{x}_t, y, \dot{y}_t, w, h\right]
\end{equation}
で表せられる．もちろん位置$(x,y)$の二階時間微分やサイズ$w,h$の一階時間微分を加えることも可能であるが，本論文では議論しない．
\par
以降の既存手法の説明では，出力される変数は第二章と同様に式\ref{eq:output1}--\ref{eq:output2}であるとする．便宜のために各式を再掲する．

\begin{equation}
    \label{eq:output1on3}
    \begin{aligned}
        S^{\text{pred}}_t &\equiv \left\{ \left. \hat{\bm{s}}_t^{(i)}\right| i \in \mathcal{I}_t\right\}
    \end{aligned}
\end{equation}
\begin{equation}
    \label{eq:output2on3}
    \begin{aligned}
        S^{\text{init}}_t &\equiv \left\{ \left. \hat{\bm{s}}_{t_s^{(i)}}^{(i)}\right| i \in \mathcal{I}_t\right\}
    \end{aligned}
\end{equation}
ここで$\hat{A}$は$A$の推定値，$\mathcal{I}_t$は時刻$t$において追跡している物体の集合，$t_s^{(i)}$は物体$i$が追跡され始めた時刻を表している．

既存手法YOLO+SORTは，物体検出手法とReID手法を組み合わせた手法である（図\ref{fig:YOLO+SORT}参照）．物体検出とは，画像内に映る物体を前述したBounding-Boxで位置検出し，さらにその物体が何であるかを同定するタスクである．``何であるか''は機械学習の分野では``クラス"と呼び，事前に犬や猫といったクラスの候補を与えておくことで，各物体がいずれのクラスに属するかを判定する．また物体検出は，画像内に複数の物体が写っている場合にもそれぞれをクラス分類できることが強みである．一方ReIDとは，検出された各Bounding-BoxにIDを振るタスクである．例えば２枚の画像内に同一個体が写っている場合には，同じIDを振ることが望まれる．これを画像時系列データに適用すれば，追跡をしていることと同義となる．
\par
以降の節で，各手法について詳細に述べる．

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{fig/yolosort.pdf}
    \caption[YOLO+SORTの処理概要]{YOLO+SORTの処理概要}
    \label{fig:YOLO+SORT}
\end{figure}

    \subsection{YOLOによる物体検出}
    YOLO（You Only Look Once）は，2016年に提案された物体検出を行う深層学習モデルである．この手法が開発される以前では，矩形領域抽出とクラス分類の処理は段階的に行われていた\cite{girshick2014rich,girshick2015fast,ren2016faster}ために処理時間に問題があったが，YOLOではそれらをすべてニューラルネットワークで処理するモデルとして提案され，その高速性から以降リアルタイム物体検出の手法として確立した．
    またリアルタイムな処理を必要とされる物体追跡にも，デファクトスタンダードとして使用される．
    \par
    YOLOの性能についてしばしば言及されるのは，推論時間と精度のトレードオフである．ここでの推論とは，一般的な機械学習モデルを学習させた後に目的のデータを入力して結果を得る操作のことをいう．一般的に，モデルの学習パラメータ数を増やすほど精度が上がる一方，推論時間は大きくなってしまい，逆もまた然りである．初期モデルのversion1（以降v1と表記する）以降，このトレードオフの改善を目指して，2024年12月時点でYOLOはv2からv10まで開発されている．図\ref{fig:v10_performance}に示すようにv10が現状では最も優れているため，以降ではv10を前提として説明を進める．

    \begin{figure}[t]
        \centering
        \includegraphics[width=\linewidth]{fig/yolov10_performance.pdf}
        \caption[yoloのバージョン比較（（左）性能と推論速度（右）性能とモデルパラメータ数）]{yoloのバージョン比較（（左）性能と推論速度（右）性能とモデルパラメータ数）: 縦軸の\textrm{COCO AP}が性能，横軸の\textrm{Latency}は推論にかかる時間，\textrm{Number of Parameters}はモデルの大きさを表す．}
        \label{fig:v10_performance}
    \end{figure}

    YOLOv10は，画像の埋め込み表現$z$を獲得する写像$f(\cdot ; \theta)$（式\ref{eq:f}）とそこから物体検出用の矩形領域抽出とクラス分類に対応する出力$y$を獲得する写像$g(\cdot ; \phi)$（式\ref{eq:g}）で構成される．

    \begin{equation}
        \label{eq:f}
        \begin{gathered}
            z = f(X; \theta)
            \\ z \in \mathbb{R}^d, \quad X \in \mathbb{R}^{W \times H \times 3}
        \end{gathered}
    \end{equation}
    \begin{equation}
        \label{eq:g}
        \begin{gathered}
            y = g(z; \phi)
            \\ y \in \mathbb{R}^{n \times \left(n_c + 5\right)}
        \end{gathered}
    \end{equation}
    ここで$d$は埋め込み表現の次元数，$W$と$H$は入力画像のピクセル幅と高さ，$n$は出力されるBounding-Boxの個数，$n_c$はクラス分類において事前に準備するクラス数である．また$\theta, \phi$は学習パラメータであり，学習ステップで最適化される．
    \par
    式\ref{eq:g}における$n_c + 5$は，Boundng-Boxの$\left[x, y, w, h\right]$に加え，$[0,1]$のConfidence-Scoreと条件付きクラス確率を表している．このConfidence-Scoreとは物体らしさを表し，各クラスに属する確率は，この物体らしさと条件付きクラス確率の積で与えられる．例えばクラスの候補に犬と猫の二つを準備し（$n_c=2$），Confidence-Scoreが$0.8$，条件付きクラス確率がそれぞれ$0.8, 0.2$となった場合は，犬である確率が$0.64$，猫である確率が$0.16$となり，その物体が犬である可能性が高い，という解釈ができる．
    \par
    またYOLOv10では，Confidence-Scoreの閾値処理を行う．すなわち，閾値$\sigma_{conf}$を定め，前述のクラス確率の最大値が$\sigma_{conf}$以下であるものを出力しない．この処理により，本来は物体ではないのに物体であると判断したもの（偽陽性という）が出力される可能性を抑えることができる．ただし閾値を大きくした場合には，本来は物体であるのに検出をしない（偽陰性という）可能性が大きくなってしまうことに注意しなければならない．
    \par
    最後にYOLOv10の学習方法について述べる．一般的に学習パラメータ数の大きいニューラルネットワークや学習データが高価である場合には，図\ref{fig:PTandFT}のようにPre-TrainingとFine-Tuningという２つのステップに分けて学習が行われる．大規模なデータセットでモデルを学習させた後（Pre-Training），その学習されたパラメターを初期値として小規模なデータセットでさらに学習パラメータを調整させる（Fine-Tuning）\cite{radford2018improving}．例えば物体検出用のモデルを構築する際に，データが安価に手に入る画像分類でPre-Trainingさせた後，物体検出用のデータセットでFine-Tuningを行う．これにより，画像の処理に適した状態から物体検出用に特化させることができ，学習の安定や高精度を図れる．また物体検出用のデータセットを大量に準備する必要もなくなる．また他にも，Pre-Trainingの際に$100$クラス分類の物体検出で学習させ，Fine-Tuningで特殊な対象$1$クラス分類の物体検出を学習させることもある．Fine-Tuningでは，埋め込み表現を得る$f(\cdot ; \theta)$の部分のみを引き継ぎ，$g(\cdot; \phi)$の部分は目的のタスク用に新しく学習し直すのが一般的である．

    \begin{figure}[t]
        \centering    
        \includegraphics[width=\linewidth]{fig/PTandFT.pdf}
        \caption[Pre-TrainingとFine-Tuning]{Pre-TrainingとFine-Tuning}
        \label{fig:PTandFT}
    \end{figure}
    
    \subsection{SORTによるReID}
    SORT（Simple Online Realtime Tracking）は，YOLOなどの物体検出によって得られたBonding-Boxの時系列データを入力とし，これらBounding-BoxにIDを振りながら各個体の軌跡を推定する，最も基礎的な手法である．このアルゴリズムは時系列データを処理するKalman Filterと時刻間の対応付けを行うHungarian Algorithmで構成される．まずはこれらの詳細を説明する．

        \subsubsection{Kalman Filter}
        Kalman Filterとは，センサーなどから得られた時系列データからシステム内部の状態を推定するための最適化アルゴリズムである．ここでは時系列データである観測変数を$\bm{o}_1, \bm{o}_2, \dots, \bm{o}_t$，システム内部の状態変数を$\bm{s}_1, \bm{s}_2, \dots, \bm{s}_t$と表記する．Kalman Filterでは状態変数$\bm{s}_t$を推定するために，その確率分布を考える．すなわち，観測系列$\bm{o}_1, \bm{o}_2, \dots, \bm{o}_t$が得られたときの状態変数$\bm{s}_t$の事後分布$p(\bm{s}_t \left| \bm{o}_1, \bm{o}_2, \dots, \bm{o}_t \right.)$を計算する．
        \par
        ベイズの定理から，所望の事後確率は
        \begin{equation}
            \label{eq:filtering1}
            p(\left. \bm{s}_t \right| \bm{o}_1,\dots, \bm{o}_t ) = \frac{p(\left. \bm{o}_t \right| \bm{o}_1,\dots, \bm{o}_{t-1}, \bm{s}_t) p(\left.\bm{s}_t\right| \bm{o}_1,\dots, \bm{o}_{t-1})}{p(\left.\bm{o}_t\right| \bm{o}_1,\dots, \bm{o}_{t-1})}
        \end{equation}
        と変形できる．また右辺の分子後半部$p(\left.\bm{s}_t\right| \bm{o}_1,\dots, \bm{o}_{t-1})$は条件付き確率の性質から，
        \begin{equation}
            \label{eq:prediction1}
            \begin{aligned}
                p(\left.\bm{s}_t\right| \bm{o}_1,\dots, \bm{o}_{t-1}) &= \int p(\left.\bm{s}_t, \bm{s}_{t-1}\right| \bm{o}_1,\dots, \bm{o}_{t-1}) d\bm{s}_{t-1}
                \\ &= \int p(\left.\bm{s}_t\right|\bm{s}_{t-1}, \bm{o}_1,\dots, \bm{o}_{t-1}) p(\left.\bm{s}_{t-1}\right| \bm{o}_1,\dots, \bm{o}_{t-1}) d\bm{s}_{t-1}
            \end{aligned}        
        \end{equation}
        と変形できる．
        \par
        式\ref{eq:filtering1},\ref{eq:prediction1}から，$p(\bm{s}_0\left|\bm{o}_0\right.) = p(\bm{s}_0)$が与えられれば全ての時刻$t=1,2,\dots,t$における$p(\bm{s}_t\left|\bm{o}_1,\dots,\bm{o}_t\right.)$が理論上は計算できる．しかしながら式\ref{eq:filtering1}における右辺の分母や式\ref{eq:prediction1}における右辺には積分が含まれるため，現実には計算できない．そのためKalman Filterでは一般的に，式\ref{eq:linear_setting}に見られる線形性及びマルコフ性をシステムに仮定している（この問題設定におけるKalman Filterを特別に一般線形Kalman Filterと呼ぶこともある）．
        \begin{equation}
            \label{eq:linear_setting}
            \begin{aligned}
                \bm{s}_{t+1} &= F_t \bm{s}_t + \bm{v}_t, \quad \bm{v}_t \sim \mathcal{N}(\bm{0}, Q_t)
                \\ \bm{o}_t &= H_t \bm{s}_t + G_t \bm{u}_t + \bm{w}_t, \quad \bm{w}_t \sim \mathcal{N}(\bm{0}, R_t)
            \end{aligned}        
        \end{equation}
        上の式は状態遷移式，下の式は観測方程式と呼ばれる．ここで$F_t$は遷移行列と呼ばれる状態変数の時間遷移を，$H_t$は観測行列と呼ばれる観測変数との対応を表す行列である．また$\bm{v}_t$はシステムノイズ，$\bm{w}_t$は観測ノイズと呼ばれ，正規性を持ったホワイトノイズである．また$\bm{u}_t$はこちら側が制御する入力変数であり，ここでは後述の問題に対応するために観測方程式に加えている．$G_t$はその入力変数が観測変数に与える影響を表す行列である．
        \par
        式\ref{eq:linear_setting}より，明らかに状態変数$\bm{s}_t$と観測変数$\bm{o}_t$はマルコフ性を持っているため，式\ref{eq:filtering1}及び式\ref{eq:prediction1}は，
        \begin{equation}
            \label{eq:filtering2}
            \begin{aligned}
                p(\left. \bm{s}_t \right| \bm{o}_1,\dots, \bm{o}_t ) &= \frac{p(\left. \bm{o}_t \right| \bm{s}_t) p(\left.\bm{s}_t\right| \bm{o}_1,\dots, \bm{o}_{t-1})}{p(\left.\bm{o}_t\right| \bm{o}_1,\dots, \bm{o}_{t-1})}
            \end{aligned}
        \end{equation}
        \begin{equation}
            \label{eq:prediction2}
            \begin{aligned}
                p(\left.\bm{s}_t\right| \bm{o}_1,\dots, \bm{o}_{t-1}) = \int p(\left.\bm{s}_t\right|\bm{s}_{t-1}) p(\left.\bm{s}_{t-1}\right| \bm{o}_1,\dots, \bm{o}_{t-1}) d\bm{s}_{t-1}
            \end{aligned}
        \end{equation}
        と書き換えられる．
        \par
        また式\ref{eq:linear_setting}より，$\bm{s}_t$及び$\bm{o}_t$は$\bm{s}_{t-1}$が正規分布に従えば，線形な式であるためにこれらもまた正規分布に従うことが分かる．すなわち$p(\bm{s}_0)$に正規分布を仮定すれば，全ての$t$で状態変数$\bm{s}_t$と観測変数$\bm{o}_t$は正規分布に従う．よって，式\ref{eq:filtering2}と式\ref{eq:prediction2}は式\ref{eq:normal_format}のように表すことができ，
        \begin{equation}
            \label{eq:normal_format}
            \begin{aligned}
                p(\left. \bm{s}_t \right| \bm{o}_1,\dots, \bm{o}_t ) &= \mathcal{N}(\bm{\mu}_{t|t}, \Sigma_{t|t})
                \\ p(\left.\bm{s}_t\right| \bm{o}_1,\dots, \bm{o}_{t-1}) &= \mathcal{N}(\bm{\mu}_{t|t-1}, \Sigma_{t|t-1})
            \end{aligned}
        \end{equation}
        以下のように状態遷移式及び観測方程式上の行列で表現でき，計算可能となる．
        \begin{equation}
            \begin{aligned}
                \bm{\mu}_{t|t-1} &= F_{t-1} \bm{\mu}_{t-1|t-1}
                \\\Sigma_{t|t-1} &= F_{t-1} \Sigma_{t-1|t-1} F_{t-1}^{\top} + Q_{t-1}
                \\\bm{\mu}_{t|t} &= \Sigma_{t|t} \left( H_t R_t^{-1} \bm{o}_t + \Sigma_{t|t-1}^{-1} \bm{\mu}_{t|t-1} \right)
                \\\Sigma_{t|t} &= \left( H_t R_t^{-1} H_t^{\top} + \Sigma_{t|t-1}^{-1}\right)^{-1}
            \end{aligned}                    
        \end{equation}
        また一般的にはKalman Gain，$K_t$を，
        \begin{equation}
            \label{eq:kalman_gain}
            K_t \equiv \Sigma_{t|t-1}H_t^{\top} \left( H_t\Sigma_{t|t-1}H_t^{\top} + R_t\right)^{-1}
        \end{equation}
        と定義して，代わりに以下の式を用いる．
        \begin{equation}
            \label{eq:kalman_equations}
            \begin{aligned}
                \bm{\mu}_{t|t-1} &= F_{t-1} \bm{\mu}_{t-1|t-1}
                \\\Sigma_{t|t-1} &= F_{t-1} \Sigma_{t-1|t-1} F_{t-1}^{\top} + Q_{t-1}
                \\\bm{\mu}_{t|t} &= \bm{\mu}_{t|t-1} + K_t \left(\bm{o}_t - H_t \bm{\mu}_{t|t-1}\right)
                \\\Sigma_{t|t} &= (I - K_t H_t) \Sigma_{t|t-1}
            \end{aligned}                    
        \end{equation}
        ここで$I$は単位行列である．

        またKalman Filterでは，事後確率が最大な点を推定値とする．すなわち観測系列$\bm{o}_1,\bm{o}_2,\dots,\bm{o}_t$が得られたときの最適状態変数推定値$\hat{\bm{s}}_{t|t}$は，
        \begin{equation}
            \begin{aligned}
                \hat{\bm{s}}_{t|t} &= \underset{\bm{s}_t \in \mathbb{R}^{n}}{\text{argmax}}\ p(\left. \bm{s}_t \right| \bm{o}_1,\dots, \bm{o}_t )
                \\ &= \bm{\mu}_{t|t}
            \end{aligned}
        \end{equation}
        で与えられる．ここで$n$は状態変数の次元数である．
        \par
        以上の議論を踏まえ，観測系列$\bm{o}_1,\bm{o}_2,\dots, \bm{o}_T$が得られた時に状態変数$\bm{s}_T$の推定値$\hat{\bm{s}}_T$を計算するアルゴリズムをアルゴリズム\ref{alg:kalman_filter}に示す．ただしここでは簡単のため，遷移行列$F_t$，観測行列$H_t$，システムノイズ共分散行列$Q_t$，観測ノイズ共分散行列$R_t$は定常であることを仮定している．

        \begin{algorithm}[t]
            \caption{Kalman Filter}
            \label{alg:kalman_filter}
            \begin{algorithmic}[1]
                \REQUIRE $\bm{o}_1,\bm{o}_2,\dots, \bm{o}_T, F, H, Q, R, \bm{\mu}_{0|0}, \Sigma_{0|0}$
                \ENSURE $\hat{\bm{s}}_T$
                \STATE \textbf{Initialize: } $\hat{\bm{s}}_t,K_t, \bm{\mu}_{t|t-1}, \Sigma_{t|t-1}, \bm{\mu}_{t|t} \leftarrow \bm{\mu}_{0|0}, \Sigma_{t|t} \leftarrow \Sigma_{0|0}$
                \FOR {$t = 1 \text{ to } T$}
                    \STATE $\bm{\mu}_{t|t-1} \leftarrow F \bm{\mu}_{t-1|t-1}$
                    \STATE $\Sigma_{t|t-1} \leftarrow F \Sigma_{t-1|t-1} F^{\top} + Q$
                    \STATE $K_t \leftarrow \Sigma_{t|t-1} H^{\top} \left(H\Sigma_{t|t-1}H^{\top} + R\right)$
                    \STATE $\bm{\mu}_{t|t} \leftarrow \bm{\mu}_{t|t-1} + K_t \left(\bm{o}_t - H\bm{\mu}_{t|t-1}\right)$
                    \STATE $\Sigma_{t|t} \leftarrow \left(I - K_t H\right) \Sigma_{t|t-1}$
                \ENDFOR
                \RETURN $\bm{\mu}_{t|t}$
            \end{algorithmic}
        \end{algorithm}

        以後，アルゴリズム\ref{alg:kalman_filter}における$3,4$行目を観測予測，$5,6,7$行目を状態更新と呼ぶことにする．

        \subsubsection{Hungarian Algorithm}
        Hungarian Algorithm\cite{kuhn1955hungarian}は，複数個のタスクを複数の作業者に最適に割り当てる，割当問題の数理アルゴリズムである．この節では，割当問題の定式化と，タスクと作業者の個数が異なる問題への適用方法を述べる．
        
        割当問題を考えるために，$n$個のタスク$a_1, a_2, \dots, a_n$とそれらのタスクを割り当てられる$n$人の作業者$b_1, b_2, \dots, b_n$が存在すると仮定する．またある作業者$b_j$がタスク$a_i$をこなしたときの成果を$s_{ij}$と定義し，この成果を並べた行列$S \in \mathbb{R}_+^{n \times n}$をスコア行列と呼ぶこととする．また，どの作業者がどのタスクをこなしたのかを示す行列を割当行列と呼び，$Q \in \{0, 1\}^{n \times n}$で表す．この$Q$の$i$行目$j$列目の成分$q_{ij}$が$1$であれば，作業者$b_j$がタスク$a_i$をこなしたことを示し，$0$であればこなしていないことを示している．

        Hungarian Algorithmの出力は，この得られる成果を最大化する割当行列$Q^*$，すなわち
        \begin{equation}
            \label{eq:assignment_objective}
            Q^* = \underset{Q}{\text{argmax}} \sum_{(i,j)} c_{ij} q_{ij}
        \end{equation}
        である．また制約として，
        \begin{equation}
            \label{eq:assignment_constraint}
            \begin{aligned}
                \sum_i q_{ij} &= 1, \quad \forall j = 1, 2, \dots, n
                \\ \sum_j q_{ij} &= 1, \quad \forall i = 1, 2, \dots, n
            \end{aligned}
        \end{equation}
        が課される．すなわち，各タスクを割り当てられるのは一人であり，一人の作業者が行うタスクもまた一つである．また作業者のいないタスクとタスクが割り当てられていない作業者もなしとしている．

        ここまでは，タスクと作業者の個数が同じ場合の割当問題を説明してきたが，一般的な割当問題では，作業者やタスクに余りがある場合も考えられる．すなわち$m$人の作業者$b_1, b_2, \dots, b_m$を考えたときに，$n \neq m$の場合も考えられる．ここでは，タスクに余りがある場合（$n > m$）には$n-m$個のタスクには作業者を割り当てず，作業者に余りがある場合（$n < m$）には$m-n$人の作業者に仕事を割り当てない問題を考える．すなわち制約\ref{eq:assignment_constraint}は，
        \begin{equation}
            \label{eq:assignment_constraint2}
            \begin{aligned}
                \sum_i q_{ij} &\in \{0, 1\}, \quad \forall j = 1, 2, \dots, n
                \\ \sum_j q_{ij} &\in \{0, 1\}, \quad \forall i = 1, 2, \dots, n
                \\ \sum_{i,j} q_{ij} &= \min (n, m)
            \end{aligned}
        \end{equation}
        と書き換えられる．

        この場合はスコア行列および割当行列が正方行列でなくなるため，Hungarian Algorithmを用いることができない．そこで，新たな行および列を足すことで正方行列を作り出すことを考える．スコア行列$S \in \mathbb{R}_+^{n \times m}$において$n > m$の場合は，要素が全て$0$の部分行列を補うことで$S \in \mathbb{R}_+^{n \times n}$とし，$n < m$の場合は同様にして$S \in \mathbb{R}_+^{m \times m}$とする．この新たに補われた部分に該当するタスクおよび作業者をダミータスクおよびダミー作業者と呼ぶことにする．

        $n > m$の場合は，いくつかのタスクがダミー作業者に割り当てられることになる．しかしダミー作業者に割り当てられると，それにより得られるスコアは$0$である．よって作業者には合計スコアを最大にするようなタスクが割り当てられるため，この解は制約\ref{eq:assignment_constraint2}のもとで計算された最適解\ref{eq:assignment_objective}と同じになる．また$n < m$の場合も同様に，ダミータスクをある作業者に割り当てた際に得られるスコアも$0$であるため，スコアが$0$より大きいタスクが優先的に作業者に割り当てられ，やはり\ref{eq:assignment_constraint2}のもとで計算された最適解と同じになる．
        
        以上の議論により，タスク数と作業者数が異なる場合にもHungarian Algorithmを適用することができる．アルゴリズム\ref{alg:hungarian_algorithm}にHungarian Algorithmをタスク集合$A$と作業者集合$B$の割当問題に適用した場合のアルゴリズムを示す．ただしここではスコアを計算する関数$f_{\text{socre}}$を使用している．また出力$M$は割当ペアの集合を表している．

        \begin{algorithm}[t]
            \caption{Hungarian Algorithm}
            \label{alg:hungarian_algorithm}
            \begin{algorithmic}[1]
                \REQUIRE $A = \left\{a_1, a_2, \dots, a_n\right\}, B = \left\{b_1, b_2, \dots, b_m\right\}$
                \ENSURE $M = \left\{(i, j) \mid Q^*_{ij} = 1 \mid i \in \left\{1, 2, \dots, n\right\}, j \in \left\{1, 2, \dots, m\right\}\right\}$
                \STATE $\textbf{Initialize: } S \in \mathbb{R}_+^{\text{max}(n, m) \times \text{max}(n, m)}$
                \FOR {$i = 0 \text{ to } \text{max}(n, m)$}
                    \FOR {$j = 0 \text{ to } \text{max}(n, m)$}
                        \IF {$ i \leq n \text{ and } j \leq m$}
                            \STATE $S_{ij} \leftarrow f_{\text{score}}(a_i, b_j)$
                        \ELSE 
                            \STATE $S_{ij} \leftarrow 0$
                        \ENDIF
                    \ENDFOR
                \ENDFOR
                \STATE $Q^* = hungarian\_algorithm(S)$
                \RETURN $\left\{(i, j) \mid Q^*_{ij} = 1 \mid i \in \left\{1, 2, \dots, n\right\}, j \in \left\{1, 2, \dots, m\right\}\right\}$
            \end{algorithmic}
        \end{algorithm}

        \subsubsection{SORTのアルゴリズム}
        ここからは，SORTの具体的な処理の流れを説明する．SORTでは，YOLOなどの物体検出によって得られたBounding-Boxの情報$\left[x, y, w, h\right]$を観測変数$\bm{o}_t$として，各物体の状態変数$\bm{s}_t$（式\ref{eq:sort_state}参照）の推定を行う．しかし，時刻$t$の画像の中には複数の物体が存在しうるため，どのBounding-Boxが時刻$t-1$まで追跡してきた物体のいずれかと同一であるかは分からない．そこで用いられるのがHungarian Algorithmによる対応付けである．これにより，時刻$t-1$まで追跡してきた個体と同一であるBounding-Boxにはその個体のIDが振られ，Kalman Filterの観測変数として利用される（図\ref{fig:sort}参照）．

        \begin{figure}[t]
            \centering
            \includegraphics[width=\linewidth]{fig/sort.pdf}
            \caption[時刻$t=4$におけるSORTの処理の概略図]{時刻$t=4$におけるSORTの処理の概略図: SORTではBounding-Boxを観測変数として状態変数の推定を行う．このときに複数のBounding-Boxを同一個体へ割り当てるために対応付けを行う．図のように，対応付けは物体検出によって得たBouning-Boxと観測予測による予測Bouding-Box間で行う．図の例では，赤色と緑色の物体は状態更新が行われている．またどの予測Bounding-Boxとも対応づかなかったものは新しい個体として認識される（黄色）．}
            \label{fig:sort}
        \end{figure}

        アルゴリズム\ref{alg:sort}に時刻$t$におけるSORTの処理を示す．13行目における$active\_tracks$関数では，時刻$t$に状態更新が行われなかったトラック集合$\mathcal{T}_{t-1}/\mathcal{T}_t$の中から，連続で状態更新されなかった回数が$\sigma_a$より小さいものを出力する．これにより，重なり合いなどで見えなくなった個体も$\sigma_a$の間に復帰すれば追跡できるようになっている．

        \begin{algorithm}[t]
            \caption{SORT}
            \label{alg:sort}
            \begin{algorithmic}[1]
                \REQUIRE $\mathcal{T}_{t-1} = \left\{ \left. T^{(i)}\right| i \in \mathcal{I}_{t-1}\right\} , \mathcal{B}_t = \left\{\left. B^{(j)} \in \mathbb{R}^{4}\right| j \in \left\{1,2,\dots,n\right\}\right\},\sigma_a$ 
                \ENSURE $\mathcal{T}_t = \left\{ \left. T^{(i)}\right| i \in \mathcal{I}_{t} \right\}$
                \STATE $\textbf{Initialize: } \mathcal{P}_t = \emptyset,\mathcal{T}_t = \emptyset, S_t^{\text{pred}} = \emptyset, S_t^{\text{init}} = \emptyset$
                \FOR {$T^{(i)} \in \mathcal{T}_{t-1}$}
                    \STATE $\hat{\bm{s}}_{t-1}^{(i)} = \text{GET}(T^{(i)},\hat{\bm{s}}_{t-1}^{(i)})$
                    \STATE $\mathcal{P}_t \leftarrow \mathcal{P}_t \cup kalman\_predict(\hat{\bm{s}}_{t-1}^{(i)})$
                \ENDFOR
                \STATE $M = hungarian\_matching(\mathcal{P}_t, \mathcal{B}_t)$
                \FOR {$(i, j) \in M$}
                    \STATE $B^{(j)} = \text{GET}(\mathcal{B}_t, B^{(j)})$
                    \STATE $\hat{\bm{s}}_t^{(i)} = kalman\_filtering(B^{(j)})$
                    \STATE $T^{(i)} \leftarrow T^{(i)} \cup \hat{\bm{s}}_t^{(i)}$
                    \STATE $S_t^{\text{pred}} \leftarrow S_t^{\text{pred}} \cup \hat{\bm{s}}_t^{(i)}$
                    \STATE $S_t^{\text{init}} \leftarrow S_t^{\text{init}} \cup \text{GET}(T^{(i)}, \hat{\bm{s}}_{t_s}^{(i)})$
                    \STATE $\mathcal{T}_t \leftarrow \mathcal{T}_t \cup T^{(i)}$
                \ENDFOR
                \STATE $\mathcal{T}_t \leftarrow active\_tracks(\mathcal{T}_{t-1} / \mathcal{T}_t, \sigma_a)$
                \RETURN $\mathcal{T}_t, S_t^{\text{pred}}, S_t^{\text{init}}$
            \end{algorithmic}
        \end{algorithm}

    \subsection{既存手法適用における問題点}
    本問題設定が既存手法における問題設定と大きく異なる点は，対象空間が３次元であり，時刻$t$における入力画像が一枚ではなく$n_s$枚あることである．これによって生じる問題点の一つ目は，追跡によって我々が得たい情報が異なることである．既存手法が対象にしている問題設定では，時刻$t_1$における個体$i$が時刻$t_2$におけるどの個体であるのか，といったことに興味がある．そのために対応付けが行われ，Kalman Filterは対応付けのためのBounding-Box予測の一手法として用いられていた．しかしながら我々の問題設定では，むしろKalman Filterの状態予測の方に興味がある．またここでいう状態変数とは，式\ref{eq:sort_state}のようなBounding-Boxの予備情報ではなく，式\ref{eq:discreation}で表せられる，３次元空間上の物理量である．すなわち，Kalman Filterの再設計が必要である．
    \par
    またこの設計に伴って，二つ目の問題が生じる．それが，観測変数をどのように得るか，という問題である．既存手法のSORTでは，一個体一時刻につき観測変数はBounding-Box一つに対応していた．もし仮に，複数のスライス画像のうちある一つのスライスを選び，その時系列画像データにYOLO+SORTを適用した場合には，Bounding-Boxの時系列データが得られる．しかしながら，この二次元空間の情報から前述した三次元空間の情報を推定することは原理的に困難である．すなわち三次元空間の物理量を推定するためには，図\ref{fig:existing_problem}のように必ず他のスライスの情報も観測変数に加えなければならない．すなわち，対応付けによってBounding-BoxにIDを割り振る際に，同時に他のスライス上のBounding-Boxにも共通のIDを割り振らなければならない．

    \begin{figure}[t]
        \centering
        \includegraphics[width=\linewidth]{fig/existing_problem.pdf}
        \caption[既存手法の問題点]{既存手法の問題点}
        \label{fig:existing_problem}
    \end{figure}

    以降の節では，まず一つ目の問題に対処するためにSliceKalmanFilterという手法を提案する．またこのSliceKalmanFilterの観測系列を得る手法として，観測予測による対応付けとSORT+DepthSORTによる対応付けの二つの手法を提案する．

\section{提案手法の設計思想}
既存手法を本問題設定に適用するうえで生じる問題点を再掲する．
\begin{enumerate}[label=(\arabic*)]
    \item SORTでは観測系列にIDを割り振ることに重きを置くが，本問題設定では三次元空間の物理量で表せられる状態を推定したい．
    \item (1)の状態を推定するために，複数のスライスにおけるBounding-Boxを観測系列に含めたい．
\end{enumerate}

まず(1)の問題に対処するために，Kalman Filterの状態変数と観測変数を三次元空間上における物理量を推定できるように書き換える．ここでは便宜上，このKalman Filterを特別にSliceKalmanFilterと呼ぶことにする．
    
\section{SliceKalmanFilterの設計}
状態変数$\bm{s}_t$は式\ref{eq:discreation}にあるように，三次元空間上の物理量を用いて，
\begin{equation}
    \label{eq:skf_state}
    \bm{s}_t = \left[x_t, \dot{x}_t, y_t, \dot{y}_t, z_t, \dot{z}_t, r_t\right]
\end{equation}
と定める．
このとき状態遷移式は一般線形Kalman Filterと同様に，
\begin{equation}
    \bm{s}_{t+1} = F_t \bm{s}_t + \bm{v}_t,\quad \bm{v}_t \sim \mathcal{N}(\bm{0}, Q_t)
\end{equation}
で表され，遷移行列$F_t$は式\ref{eq:time_transition}を満たすように設計される．また半径$r_t$は定常であることを仮定している．
\par
一方観測変数は問題点(2)で述べたように，複数のスライスにおけるBounding-Boxでなければいけない．しかしここで一度，状態変数$\bm{s}_t$からあるスライス$s$のBounding-Box$\bm{o}_s$を出力する関数$h_s(\cdot)$を考える．すると$h_s(\bm{s}_t)$は，
\begin{equation}
    \label{eq:single_map}
    h_s(\bm{s}_t) = \left\{
        \begin{aligned}
            &\left[x_{t'}, y_{t'}, 2\sqrt{r_{t'}^2 - \left(z_{t'} - z(s)\right)^2} \right]& &\quad \textbf{if }r_{t'} > \left| z_{t'} - z(s) \right|,
            \\ &\text{None}& &\quad \textbf{else }
        \end{aligned}
    \right.
\end{equation}
と表せられる．ここで各変数の添字$t'$は，2.3節で述べた撮影にかかる時間差を考慮した時刻を表している．時刻$t$のあるスライス$s$が撮影される時刻は，$s=1$のスライスと比較して$s$分時間差が生じている．すなわち時間差を考慮した時刻$t'$は，
\begin{equation}
    \label{eq:time_with_lag}
    t' = t + \frac{s-1}{n_s}
\end{equation}
で表せられることに注意されたい．

式\ref{eq:single_map}は，，状態変数$\bm{s}_t$の値によって，予測する観測変数$H_t \bm{s}_t$の次元数が可変であることを示している．さらに当然ながら，個体の大きさやタイミングによってその個体が存在しないスライスが生じるため，得られる観測変数$\bm{o}_t$の次元数も可変である．しかし式\ref{eq:kalman_equations}に着目すると，これら二者の次元数は一致していなければならないことが分かる．
\par
以上の議論より，\ref{eq:single_map}において右辺の条件式$r_{t'} > \left| z_{t'} - z(s) \right|$を満たすスライスの集合を$\mathcal{S}^{\text{pred}}_t$，Bounding-Boxが観測されたスライスの集合を$\mathcal{S}_t^{\text{obs}}$として，観測変数を以下のように集合として定義する．
\begin{equation}
    \label{eq:skf_obs}
    \begin{aligned}
        \mathcal{O}_t &= \left\{\left.\bm{o}_s\right| s \in \mathcal{S}_t^{\text{pred}} \cap \mathcal{S}_t^{\text{obs}} \subset \left\{1,2,\dots,n_s\right\} \right\}
        \\ \bm{o}_s &= \left[x_s, y_s, w_s, h_s\right]
    \end{aligned}    
\end{equation}
またこのとき観測方程式は，式\ref{eq:single_map}を用いて，
\begin{equation}
    \label{eq:skf_obs_eq}
    \bm{o}_s = h_s(\bm{s}_t) + \bm{w}_{t,s}, \quad \bm{w}_{t,s} \sim \mathcal{N}(\bm{0}, R_{t}),\quad \forall s \in \mathcal{S}_t^{\text{pred}} \cap \mathcal{S}_t^{\text{obs}}
\end{equation}
と表せられる．
\par
式\ref{eq:skf_obs_eq}では，観測変数と状態変数が非線形な関係$h_s(\cdot)$で結ばれている．このままでは前述のKalman Filterの演算を実行できないため，ExpandKalmanFilter（拡張カルマンフィルタ）の枠組みを利用する．まずは非線形な観測写像$h(\bm{s}_t)$の線形化を行うために，ある推定値$\hat{\bm{s}}_t$周りで一次Taylor展開を行って，
\begin{equation}
    \begin{aligned}
        h(\bm{s}_t) &= h(\hat{\bm{s}}_t) + \left.\frac{\partial h}{\partial \bm{s}_t}\right|_{\bm{s}_t=\hat{\bm{s}}_t} \left(\bm{s}_t - \hat{\bm{s}}_t\right) + \mathcal{O}(\bm{s}_t^2)
        \\ &= \left.\frac{\partial h}{\partial \bm{s}_t}\right|_{\bm{s}_t=\hat{\bm{s}}_t} \bm{s}_t + h(\hat{\bm{s}}_t) - \left.\frac{\partial h}{\partial \bm{s}_t}\right|_{\bm{s}_t=\hat{\bm{s}}_t} \hat{\bm{s}}_t + \mathcal{O}(\bm{s}_t^2)
    \end{aligned}
\end{equation}
と変形できる．ここで右辺第一項を$H_t \bm{s}_t$，第二項以降を$G_t \bm{u}_t$とおくと，式\ref{eq:linear_setting}の観測方程式と一致することが分かる．よって$H_t$を$\left.\partial h / \partial \bm{s}_t\right|_{\bm{s}_t=\hat{\bm{s}}_t}$，$H_t \bm{s}_t + G_t \bm{u}_t$を$h(\bm{s}_t)$とすれば一般線形Kalman Filterと同様の演算で推定値を求めることができる．またある推定値$\hat{\bm{s}}_t$には$\bm{\mu}_{t|t-1}$を用いればよい．

\section{スライス３次元画像におけるReID}

次に観測変数集合$\mathcal{O}_t$をどのように得るかを説明する．ここでの入力は，ある時刻$t$で取得された複数のスライス画像$\mathcal{X}_t$（\ref{eq:input_images}参照）を物体検出に入力して得られたBounding-Boxの集合$\mathcal{B}_t$である．ただしスライスが異なるBounding-Boxを区別するため，以下のような集合であるとする．すなわち$\mathcal{B}_{t,s}$が，時刻$t$のスライス$s$から得られたBounding-Boxの集合を表す．
\begin{equation}
    \label{eq:input_bboxes}
    \begin{aligned}
        \mathcal{B}_t &= \left\{\left.\mathcal{B}_{t,s}\right|s \in \left\{1,2,\dots,n_s\right\}\right\}
        \\\mathcal{B}_{t,s} &= \left\{\left.\bm{o}_{t,s}^{(i)}\right|i \in \mathbb{N}_{+}\right\}
    \end{aligned}
\end{equation}

我々の目的は，この$\mathcal{B}_t$のうち，どのBounding-Boxが時刻$t-1$まで追跡してきた個体由来のものであるかを対応付けさせ，また対応づかないものには新しい追跡対象として新しいIDを付与することである．すなわちここでの出力$\mathcal{B}_t^{\text{reid}}$は，
\begin{equation}
    \begin{aligned}
        \mathcal{B}_t^{\text{reid}} &= \left\{\left.\mathcal{O}_t^{(i)}\right| i \in \mathcal{I}_t\right\}
        \\ \mathcal{O}_t^{(i)} &= \left\{\left.\bm{o}_{t,s}^{(i)}\right| s \in \mathcal{S}_t^{\text{obs},(i)} \subset \left\{1,2,\dots,n_s\right\}\right\}
    \end{aligned}
\end{equation}
と表せられる．ここで$\mathcal{I}_t$は時刻$t$で追跡している個体IDの集合，$\mathcal{S}_t^{\text{obs},(i)}$は時刻$t$において個体$i$に対応付けられたBounding-Boxが検出されたスライスの集合である．
\par
$\mathbb{B}_t^{\text{reid}}$を得るための直感的な手法は，既存手法SORTと同様に，状態変数から各スライスで検出されるBouding-Boxを予測し，それらと実際に検出されたBounding-Boxを比較し，Hungarian Algorithmなどによって対応付ける手法である．まずはこちらの手法について説明する．

    \subsection{SliceKalmanFilter予測によるマッチング}
    時刻$t-1$までに$\left|\mathcal{I}_{t-1}\right|$個の個体を追跡できており，それぞれの状態変数推定値$\hat{\bm{s}}_{t-1}^{(i)}$を計算済みであると仮定する（ただし$i \in \mathcal{I}_{t-1}$）．
    \par
    式\ref{eq:single_map}によりこれらの状態変数から，時刻$t$に得られるBounding-Box集合$\mathcal{B}_t$に対応する予測集合$\mathcal{B}_t^{\text{pred}}$を得ることができる．すなわち，
    \begin{equation}
        \begin{aligned}
            \mathcal{B}_t^{\text{pred}} &= \left\{\left.B_{t,s}^{\text{pred}}\right|s \in \left\{1,2,\dots,n_s\right\}\right\}
            \\ B_{t,s}^{\text{pred}} &= \left\{\left.\bm{o}_{t,s}\right| \bm{o}_{t,s} \in \mathcal{P}_{t,s} \subset \mathcal{P}_t\right\}
            \\ \mathcal{P}_t &= \bigcup_{i \in \mathcal{I}_{t-1}} \left\{\left.h_s(\hat{\bm{s}}_{t-1})\right| s \in \mathcal{S}_{t-1}^{\text{pred},(i)}\right\}
        \end{aligned}
    \end{equation}
    ここで$\mathcal{P}_{t,s}$は予測されたBounding-Box集合$\mathcal{P}_t$のうちスライス$s$における予測の集合，$\mathcal{S}_{t-1}^{\text{pred},(i)}$は時刻$t-1$において個体$i$の状態変数推定値$\bm{s}_{t-1}^{(i)}$が式\ref{eq:single_map}の右辺の条件式を満たすことができるスライスの集合を表している．
    \par
    これらスライスごとの予測集合$\mathcal{P}_{t,s}$と観測集合$\mathcal{B}_{t,s}$があれば，SORTと同様にHungarian Algorithmによる対応付けが可能である．以上の流れをアルゴリズム\ref{alg:skf_matching}に示す．
    \begin{algorithm}[t]
        \caption{Sliced-ReID by SKF's Prediction}
        \label{alg:skf_matching}
        \begin{algorithmic}[1]
            \REQUIRE $\mathcal{T}_{t-1} = \left\{ \left. T^{(i)}\right| i \in \mathcal{I}_{t-1}\right\} , \mathcal{B}_t = \left\{\left. \mathcal{B}_{t,s} \right| s \in \left\{1,2,\dots,n_s\right\}\right\},\sigma_a$ 
            \ENSURE $\mathcal{B}_t^{\text{reid}} = \left\{\left.\mathcal{O}_t^{(i)}\right|i \in \mathcal{I}_t\right\}$
            \STATE $\textbf{Initialize: } \mathcal{T}_t = \emptyset, \mathcal{I}_t = \emptyset,\mathcal{P}_{t,1} = \mathcal{P}_{t,2}=\dots=\mathcal{P}_{t,n_s} = \emptyset$
            \FOR {$T^{(i)} \text{ in } \mathcal{T}_{t-1}$}
                \FOR {$s = 1 \text{ to } n_s$}
                    \STATE $\hat{\bm{s}}_{t-1}^{(i)} = \text{GET}(T^{(i)}, \hat{\bm{s}}_{t-1}^{(i)})$
                    \STATE $\mathcal{P}_{t,s} \leftarrow \mathcal{P}_{t,s} \cup h_s(\hat{\bm{s}}_{t-1}^{(i)})$
                \ENDFOR
            \ENDFOR
            \FOR {$s = 1 \text{ to } n_s$}
                \STATE $M_{t,s} = hungarian\_matching(\mathcal{P}_{t,s}, \mathcal{B}_{t,s})$
                \FOR {$(i,j) \text{ in } M_{t,s}$}
                    \STATE $\bm{o}_{t,s}^{(j)} = \text{GET}(\mathcal{B}_{t,s})$
                    \STATE $\mathcal{O}_t^{(i)} = \left\{\bm{o}_{t,s}^{(j)}\right\} \textbf{ if } \mathcal{O}_t^{(i)} \text{ is undefined} \textbf{ else } \mathcal{O}_t^{(i)} \leftarrow \mathcal{O}_t^{(i)} \cup \bm{o}_{t,s}^{(j)}$
                    \STATE $\mathcal{I}_t \leftarrow \mathcal{I}_t \cup i$
                \ENDFOR
            \ENDFOR
            \RETURN $\left\{\left.\mathcal{O}_t^{(i)}\right|i \in \mathcal{I}_t\right\}$
        \end{algorithmic}
    \end{algorithm}

    また時刻$t=1$における対応付では，（保留！！KFの方も書き換えなきゃ）
    \par
    しかしながらこの手法には懸念点が一つある．それは，式\ref{eq:skf_obs}において観測変数の集合を構築する際に，予測が存在するスライス集合$\mathcal{S}_t^{\text{pred}}$と観測が存在するスライス集合$\mathcal{S}_t^{\text{obs}}$の積集合にのみ着目している点である．これにより，物体検出の偽陰性や状態変数の推定に大きな誤差があったときに観測変数の情報は希薄になってしまい，さらなる推定精度の低下に繋がりかねない．
    \par
    この懸念点に対応するために，SORTのような二次元空間における物体追跡情報を利用した手法を次節で提案する．

    \subsection{SORT+DepthSORTによるマッチング}
    SliceKalmanFilterの観測予測による対応付けでは，一度状態変数を推定した後，その推定値をもとにBounding-Boxの位置を予測して対応付けに利用していた．しかしながら対応付けを考えるうえでは，単一スライスに着目して一時刻前のBounding-Boxを参照したり，もしくは単一時刻における上下のスライスのBounding-Boxを参照したりした方がより直感的であり，より有効である可能性がある．特に状態変数の推定の精度が低い場合には，単一スライスや単一時刻の別スライスに着目したほうが予測は安定する．
    \par
    以上の議論から本節では，状態推定と対応付けに利用するKalman Filterを区別し，既存手法のSORTを拡張することでより安定したBounding-Boxの予測を目指した手法を提案する．
    \par
    既存手法のSORTは，時刻$1$から$t-1$までの観測系列から時刻$t$のBounding-Boxを予測し，対応付けに利用していた．単一のスライスに着目すれば，ただ一つのBounding-Boxの変位及び速度そのものを推定するため，前述のSliceKalmanFilterよりも安定した予測が可能である．しかしながらこの手法のみでは，各スライスで追跡されている個体同士の対応付けができない．
    \par
    そこでここでは，深さ方向へSORTを適用する．すなわち時刻$t$のBounding-Box集合$\mathcal{B}_t$（式\ref{eq:input_bboxes}参照）が得られた時に，$s=1$のBounding-Box集合$\mathcal{B}_{t,s=1}$を初期時刻の入力，$s=n_s$のBounding-Box集合$\mathcal{B}_{t,s=n_s}$を終了時刻の入力とみなしたSORTを実施する．このアルゴリズムをDepthSORTと呼ぶこととする．これにより同一個体由来のBounding-Boxには同じIDが割り振られるため，個体ごとのBounding-Box集合$\mathcal{B}_t^{DS} = \left\{\left.\mathcal{B}_t^{DS, (j)}\right|j \in \mathcal{I}_t^{DS}\right\}$に分けることができる．ここで$\mathcal{I}_t^{DS}$はDepthSORTによりBounding-Boxを仕分けた際の臨時個体IDの集合を表す．このDepthSORTのアルゴリズムをアルゴリズム\ref{alg:DepthSORT}に示す．
    \begin{algorithm}[t]
        \caption{DepthSORT}
        \label{alg:DepthSORT}
        \begin{algorithmic}[1]
            \REQUIRE $\mathcal{B}_t = \left\{\left.\mathcal{B}_{t,s}\right|s \in \left\{1,2,\dots,n_s\right\}\right\}, \sigma_a$
            \ENSURE $\mathcal{B}_t^{DS} = \left\{\left.\mathcal{B}_t^{DS, (j)}\right|j \in \mathcal{I}_t^{DS}\right\}$
            \STATE $\textbf{Initialize: } \mathcal{P}_s = \emptyset, \mathcal{B}_t^{DS}=\emptyset$
            \FOR {$\bm{o}^{(j)} \text{ in } \mathcal{B}_{t,s=1}$}
                \STATE $\mathcal{B}_t^{DS, (j)} = \left\{\bm{o}^{(j)}\right\}$ 
                \STATE $\mathcal{B}_t^{DS} \leftarrow \mathcal{B}_t^{DS} \cup \mathcal{B}_t^{DS, (j)}$
            \ENDFOR
            \FOR {$s = 2 \text{ to } n_s$}
                \FOR {$ \mathcal{B}_t^{DS, (j)} \text{ in }\mathcal{B}_t^{DS}$}
                    \STATE $\mathcal{P}_s \leftarrow \mathcal{P}_s \cup kalman\_predict(\mathcal{B}_t^{DS, (j)})$
                \ENDFOR
                \STATE $M_{s} = hungarian\_matching(\mathcal{P}_s, \mathcal{B}_{t,s})$
                \FOR {$(i,j) \text{ in } M_s$}
                    \STATE $\bm{o}^{(j)} = \text{GET}(\mathcal{B}_{t,s})$
                    \STATE $\mathcal{B}_t^{DS,(i)} \leftarrow \mathcal{B}_t^{DS,(i)} \cup \bm{o}^{(j)}$
                \ENDFOR
                \STATE $\mathcal{B}_t^{DS} \leftarrow active\_tracks(\mathcal{B}_t^{DS}, \sigma_a)$
            \ENDFOR
            \RETURN $\mathcal{B}_t^{DS}$
        \end{algorithmic}
    \end{algorithm}

    しかしDepthSORTだけでは，時刻$t-1$まで追跡してきた個体IDの集合$\mathcal{I}_{t-1}$と$\mathcal{I}_t^{DS}$は対応づいていない．そのため，最後にSORTとDepthSORTの結果を統合することでこれらのIDを対応付け，最終的な出力$\mathcal{B}_t^{\text{reid}}$を得る．
    \par
    ここで新たに，対応付けのための個体$i$の追跡情報を$S_t^{(i)}$と表し，これは二次元的な各スライスの状態変数推定値の集合だとする．すなわち，
    \begin{equation}
        \begin{aligned}
            S_t^{(i)} &= \left\{\left.\hat{\bm{s}}_{t,s}^{(i)}\right| s \in \mathcal{S}^{\text{bbox}}_t\right\}
        \end{aligned}
    \end{equation}
    と表せられる．ここで$\mathcal{S}_t^{\text{bbox}}$は，ある個体$i$が時刻$t$において検出されているスライスの集合を表す．つまり状態推定用のKalman Filterとは異なり，スライスごとに状態変数を保持している．またこの式における状態変数は三次元空間上の物理量で表されるものではなく，二次元的なBounding-Boxから得られる物理量で表されるものである．
    \par
    まずはこれらの各スライスの状態推定値を用いて，時刻$t$のBounding-Boxの予測$\mathcal{B}_t^{\text{pred}}$を構築する．ただしこれらは以下のようにスライスごとの状態推定値から計算される．
    \begin{equation}
        \begin{aligned}
            \mathcal{B}_t^{\text{pred}} &= \left\{\left.\mathcal{B}_{t,s}^{\text{pred}}\right|s \in \left\{1,2,\dots,n_s\right\}\right\}
            \\ \mathcal{B}_{t,s}^{\text{pred}} &= \left\{\left.kalman\_predict(\hat{\bm{s}}_{t-1,s}^{(i)})\right|i \in \mathcal{I}_{t-1}\right\}
        \end{aligned}
    \end{equation}
    ここからはSliceKalmanFilterの対応付けと同様に，スライスごとに予測と観測の対応付けを行い，IDが割り振られたBounding-Box集合$\mathcal{B}_t^{S}$を得る．
    \par
    最後に，DepthSORTによって得られたBounding-Box集合$\mathcal{B}_t^{DS}$とSORTによって得られたBounding-Box集合$\mathcal{B}_t^{S}$の対応付けを行い，追跡してきた個体のIDであるSORT側のIDをDepthSORTの集合へ割り当てる．ここでは$\mathcal{B}_t^{S, (i)}$と$\mathcal{B}_t^{DS, (j)}$がいくつ共通のBounding-Boxを持っているかの個数をHungarian Matchingで用いるスコア行列の$ij$成分とする．
    以上の流れをアルゴリズム\ref{alg:SORT+DepthSORT}にまとめる．また，図\ref{fig:sort+depthsort}に本手法の概略図を示す．

    \begin{algorithm}[t]
        \caption{SORT+DepthSORT}
        \label{alg:SORT+DepthSORT}
        \begin{algorithmic}[1]
            \REQUIRE $S_{t-1} = \left\{\left.S_{t-1}^{(i)}\right| i \in \mathcal{I}_{t-1}\right\}, \mathcal{B}_t = \left\{\left.\mathcal{B}_{t,s} \right| s \in \left\{1, 2, \dots, n_s\right\}\right\}$
            \ENSURE $\mathcal{B}_t^{\text{reid}} = \left\{\left.\mathcal{O}_t^{(i)}\right|i \in \mathcal{I}_t\right\}$
            \STATE $\textbf{Initialize: } \text{あとまわし}$
            \FOR {$s = 1 \text{ to } n_s$}
                \STATE $\mathcal{P}_{t,s} = \emptyset$
                \FOR {$S_{t-1}^{(i)} \text{ in } S_{t-1}$}
                    \STATE $\hat{\bm{s}}_{t,s}^{(i)} = \text{GET}(S_{t-1}^{(i)})$
                    \STATE $\mathcal{P}_{t,s} \leftarrow \mathcal{P}_{t,s} \cap kalman\_predict(\hat{\bm{s}}_{t,s}^{(i)})$
                \ENDFOR
                \STATE $M_{t,s} = hungarian\_matching(\mathcal{P}_{t,s}, \mathcal{B}_{t,s})$
                \FOR {$(i,j) \text{ in } M_{t,s}$}
                    \STATE $\bm{o}_{t,s}^{(j)} = \text{GET}(\mathcal{B}_{t,s})$
                    \STATE $\mathcal{B}_t^{S,(i)} = \left\{\bm{o}_{t,s}^{(j)}\right\} \textbf{ if } \mathcal{B}_t^{S,(i)} \text{ is undefined} \textbf{ else } \mathcal{B}_t^{S,(i)} \leftarrow \mathcal{B}_t^{S,(i)} \cap \bm{o}_{t,s}^{(j)}$
                    \STATE $\mathcal{I}_t^{S} \leftarrow \mathcal{I}_t^{S} \cap i$
                \ENDFOR
                \STATE $\mathcal{B}_t^{S} = \left\{\left.\mathcal{B}_t^{S,(i)}\right|i \in \mathcal{I}_t^{S}\right\}$
            \ENDFOR
            \STATE $\mathcal{B}_t^{DS} = depth\_sort(\mathcal{B}_t, \sigma_a)$
            \STATE $M_{(S,DS)} = hungarian\_matching(\mathcal{B}_t^{S}, \mathcal{B}_t^{DS})$
            \FOR {$(i,j) \text{ in } M_{(S,DS)}$}
                \STATE $\mathcal{O}_t^{(i)} = \mathcal{B}_t^{DS, (j)}$
                \STATE $\mathcal{I}_t \leftarrow \mathcal{I}_t \cap i$
            \ENDFOR
            \RETURN $\left\{\left.\mathcal{O}_t^{(i)}\right| i \in \mathcal{I}_t\right\}$
        \end{algorithmic}
    \end{algorithm}

    \begin{figure}[t]
        \centering
        \includegraphics[width=\linewidth]{fig/sort+depthsort.pdf}
        \caption[SORT+DepthSORTの概略図]{SORT+DepthSORTの概略図}
        \label{fig:sort+depthsort}
    \end{figure}
