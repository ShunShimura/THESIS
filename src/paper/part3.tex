\thispagestyle{fancy2}

\section{既存手法と問題点}
画像の時系列データを入力として，オンライン処理で複数の物体を追跡する問題は，複数物体追跡（Multi Object Tracking; MOT）と呼ばれ\cite{luo2021multiple}，防犯カメラに映る歩行者や自動車の追跡などに広く用いられている．しかしながらこれらの手法のほとんどが３次元（空間２次元+時間）データにしか対応していない．特に，本問題のようなスライスとして入力される４次元データをそのまま適用できる手法は未だ開発されていない．
\par
そのためこの章では，まずはじめにMOT問題にしばしば使用されるYOLO+SORT\cite{redmon2016you,alif2024yolov1,bewley2016simple}を既存手法として説明し，その後にそれらを基盤とした提案手法の説明に移る．

\subsection{２次元画像の系列データに対する複数物体追跡}
既存手法の説明の前に，それらの手法が解いている問題設定を先に述べる．
\begin{description}
    \item[処理] 時刻$t$で制御されるオンライン処理．ただし時間間隔$dt$は，カメラなどのフレームレートに依存する．
    \item[入力] 各時刻$t$において，一枚の画像データが与えられる．ただしここでは簡単のため，常に同じ画角で得られた画像を仮定する．
    \item[出力] 時刻$t$で追跡している各物体の状態ベクトル．ここで状態ベクトルとは，位置や速度，大きさなどの情報を含むベクトルのことである．
\end{description}
すなわち，前節で説明した問題設定において，画像データが複数のスライスではなく単一のスライスに変化しただけと考えれば良い．
\par
YOLO+SORTでは，前述の問題を物体検出とReIDという２つの処理に段階的に分けて解く．物体検出とは，ある画像を入力したときに，物体の存在する範囲をバウンディングボックスと呼ばれる矩形領域で検出し，なおかつ犬や猫，自動車といったクラス分類も同時に行うタスクのことをいう．また，画像内に複数の物体が存在していても，すべての各物体に対して同時に矩形領域検出・クラス分類を行う．YOLO（You Only Look Once）は，この物体検出用に開発された深層学習モデルである．またSORT（Simple Online Realtime Tracking）は，YOLOのような物体検出モデルから出力されたバウンディングボックスを入力とし，各個体の軌跡を推定する（図\ref{fig:yolosort}参照）．

\begin{figure}[h]
    \centering    
    \includegraphics[width=.5\textwidth]{fig/nagoya-u.eps}
    \caption{YOLO+SORTの処理}
    \label{fig:yolosort}
\end{figure}

後述の提案手法では，YOLOの処理には変更を加えず，ReIDを４次元データ用に拡張してゆく．そのため，その基盤となるSORTの処理について，詳細を述べる．
\par
まず入力として，YOLOから出力される時刻$t=1,2,...,T$のバウンディングボックス群$O_t = \left\{\bm{o}_t^1, \bm{o}_t^2,...\right\}$が得られていると仮定する．ここで，各バウンディングボックス$\bm{o}_t^i$は，矩形領域を表す中心位置$(x,y)$と幅$w$，高さ$h$の４変数ベクトルである． SORTではこれらの入力に対して以下の処理（図\ref{fig:sort}参照）を時刻$1$から$T-1$まで繰り返し，各個体を表すIDで識別された状態変数配列$S_t = \left[\bm{s}_t^1, \bm{s}_t^2,...\right]$を返す．ここで$\bm{s}_t$は，位置や速度，大きさなどの情報を含んでいる．

\begin{enumerate}
    \item 各個体の状態変数$S_t$から，時刻$t+1$のバウンディングボックス配列の予測$\hat{O}_{t+1}$をカルマンフィルタ\cite{adachi2012kalman}の時間更新によって計算する．ただし$t=1$の場合は$\hat{O}_{t+1} \leftarrow O_t$とする．
    \item 予測されたバウンディングボックス配列$\hat{O}_{t+1}$と与えられた$O_{t+1}$を比較し，いずれの組み合わせが同個体であるかを最適化する．
    \item 各状態変数$\bm{s}_t^i$を，それに対応付けられたバウンディングボックス$\bm{o}_{t+1}^i$を用いて更新して$\bm{s}_{t+1}^i$とし，$S_{t+1}$に加える．
\end{enumerate}

\begin{figure}[h]
    \centering    
    \includegraphics[width=\textwidth]{fig/sort.pdf}
    \caption{SORTのアルゴリズム概要}
    \small
    SORTでは予測，マッチング，更新を時刻$1$から$T-1$まで繰り返す．ただし予測と更新はカルマンフィルタによって行われる．ただしこの図では分かりやすさのために状態変数$\bm{s}_t$を用いずに観測系列$\bm{o}_1,...,\bm{o}_t$で図示している．実際には観測系列を記憶する必要はなく，前時刻の状態変数$\bm{s}_t$のみで予測計算を行う点に注意されたい．
    \label{fig:sort}
\end{figure}

前述の既存手法，YOLO+SORTをそのまま本問題設定に適用することはできない．なぜならば，時刻$t$における入力は画像一枚ではなく，共焦点顕微鏡によって得られた複数の画像であるためだ．もちろん複数のスライスを個別に扱い，単一スライスごとにYOLO+SORTを適用することは可能である．しかしながら物体が鉛直方向に移動する場合には，いずれ対象物体がスライスの高さから外れ，追跡できなくなってしまう．またその場合には，各スライスで得られた各個体の軌跡を，事後的に統合するフレームワークが必要になり，問題が複雑になってしまう．
\par
そこで以下の節では，各時刻で他のスライスを考慮した追跡手法を提案する．

\section{提案手法の概要}
まず初めに，提案手法の設計思想を説明するために，従来の３次元（空間２次元＋時間）複数物体追跡と比較した本問題のような４次元（空間３次元＋時間）複数物体追跡のポイントを述べる．
\begin{enumerate}
    \item 鉛直方向に動く物体を追跡したい．本問題では３次元空間を複数の２次元画像で捉えているため，高さごとにスライスを独立して処理をすると，鉛直方向に動く物体を追従できない．
    \item ３次元空間における状態変数を推定したい．従来の３次元複数物体追跡では，バウンディングボックスに含まれる変数$[x,y,w,h]$及びその速度が目的の状態変数であった．しかしながら，４次元複数物体追跡における目的の状態変数は，３次元的な位置や速度である．すなわち，SORTの内部で働くカルマンフィルタの再設計が必要である．
\end{enumerate}

以上の点を踏まえ，前述のYOLO+SORTの処理に加えて，他のスライスを参照する\textbf{Depth-SORT}と\textbf{SliceKalmanFilter}という処理・計算手法を提案する．提案手法の概要は以下の通りである（図\ref{fig:proposal}参照）．

\begin{enumerate}
    \item 物体検出: YOLOv10により，画像を入力してその画像内の物体をバウンディングボックス$[x,y,w,h]$で検出する．
\end{enumerate}

\section{物体検出: YOLOv10}

\section{ReID: SORT+DepthSORT}

\section{状態変数の推定: SliceKalmanFilter}