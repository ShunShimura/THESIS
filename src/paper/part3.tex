\thispagestyle{fancy2}

画像の時系列データを入力として，オンライン処理で複数の物体を追跡する問題は，複数物体追跡（Multi-Object Tracking; MOT）と呼ばれ，\cite{luo2021multiple}，防犯カメラに映る歩行者や自動車の追跡など，広く利用されている．しかしながらこれらの手法のほとんどは，一時刻に画像が一枚入力される３次元データにしか対応していない．特に，本問題設定のように３次元の空間情報が複数のスライス画像で与えられる４次元データにそのまま適用できる手法は未だ開発されていない．
\par
よってこの章では，新たに本問題設定のような問題に適用できるような手法を提案する．また提案手法の基盤として，一般的な複数物体追跡問題にしばしば利用されるYOLO+SORT\cite{redmon2016you,alif2024yolov1,bewley2016simple}を説明する．

\section{既存手法と問題点}
既存手法が対象にしている問題設定では，前述の通り一時刻の入力が画像一枚である．またYOLO+SORTでは，物体の情報をBounding-Boxと呼ばれる矩形情報$\left[x, y, w, h\right]$で表現する．ここで$(x,y)$は画像における物体の位置，$w$は物体の幅，$h$は物体の高さである．よって推定される物体の状態変数$\bm{s}_t$は，このBounding-Boxの持つ変数及びそれらの時間微分で与えられる．
\par
以上の議論から，既存手法が対象にしている問題における，時刻$t$の入力データ$\mathcal{X}_t$は，

\begin{equation}
    \mathcal{X}_t \in \mathbb{R}^{W \times H \times 3}
\end{equation}
で表せられ，物体の状態変数$\bm{s}_t$は，

\begin{equation}
    \label{eq:sort_state}
    \bm{s}_t \equiv \left[x_t, \dot{x}_t, y, \dot{y}_t, w, h\right]
\end{equation}
で表せられる．もちろん位置$(x,y)$の二階時間微分やサイズ$w,h$の一階時間微分を加えることも可能であるが，本論文では議論しない．
\par
以降の既存手法の説明では，出力される変数は第二章と同様に式\ref{eq:output1}--\ref{eq:output2}であるとする．便宜のために各式を再掲する．

\begin{equation}
    \label{eq:output1on3}
    \begin{aligned}
        S^{\text{pred}}_t &\equiv \left\{ \left. \hat{\bm{s}}_t^{(i)}\right| i \in \mathcal{I}_t\right\}
    \end{aligned}
\end{equation}
\begin{equation}
    \label{eq:output2on3}
    \begin{aligned}
        S^{\text{init}}_t &\equiv \left\{ \left. \hat{\bm{s}}_{t_s^{(i)}}^{(i)}\right| i \in \mathcal{I}_t\right\}
    \end{aligned}
\end{equation}
ここで$\hat{A}$は$A$の推定値，$\mathcal{I}_t$は時刻$t$において追跡している物体の集合，$t_s^{(i)}$は物体$i$が追跡され始めた時刻を表している．

既存手法YOLO+SORTは，物体検出手法とReID手法を組み合わせた手法である（図\ref{fig:YOLO+SORT}参照）．物体検出とは，画像内に映る物体を前述したBounding-Boxで位置検出し，さらにその物体が何であるかを同定するタスクである．``何であるか''は機械学習の分野では``クラス"と呼び，事前に犬や猫といったクラスの候補を与えておくことで，各物体がいずれのクラスに属するかを判定する．また物体検出は，画像内に複数の物体が写っている場合にもそれぞれをクラス分類できることが強みである．一方ReIDとは，検出された各Bounding-BoxにIDを振るタスクである．例えば２枚の画像内に同一個体が写っている場合には，同じIDを振ることが望まれる．これを画像時系列データに適用すれば，追跡をしていることと同義となる．
\par
以降の節で，各手法について詳細に述べる．

\begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{fig/yolosort.pdf}
    \caption{YOLO+SORTの処理概要}
    \label{fig:YOLO+SORT}
\end{figure}

    \subsection{YOLOによる物体検出}
    YOLO（You Only Look Once）は，2016年に提案された物体検出を行う深層学習モデルである．この手法が開発される以前では，矩形領域抽出とクラス分類の処理は段階的に行われていた\cite{girshick2014rich,girshick2015fast,ren2016faster}ために処理時間に問題があったが，YOLOではそれらをすべてニューラルネットワークで処理するモデルとして提案され，その高速性から以降リアルタイム物体検出の手法として確立した．
    またリアルタイムな処理を必要とされる物体追跡にも，デファクトスタンダードとして使用される．
    \par
    YOLOの性能についてしばしば言及されるのは，推論時間と精度のトレードオフである．ここでの推論とは，一般的な機械学習モデルを学習させた後に目的のデータを入力して結果を得る操作のことをいう．一般的に，モデルの学習パラメータ数を増やすほど精度が上がる一方，推論時間は大きくなってしまい，逆もまた然りである．初期モデルのversion1（以降v1と表記する）以降，このトレードオフの改善を目指して，2024年12月時点でYOLOはv2からv10まで開発されている．図\ref{fig:v10_performance}に示すようにv10が現状では最も優れているため，以降ではv10を前提として説明を進める．

    \begin{figure}[t]
        \centering
        \includegraphics[width=\textwidth]{fig/yolov10_performance.pdf}
        \caption{yoloのバージョン比較（（左）性能と推論速度（右）性能とモデルパラメータ数）}
        \small
        縦軸の\textrm{COCO AP}が性能，横軸の\textrm{Latency}は推論にかかる時間，\textrm{Number of Parameters}はモデルの大きさを表す．
        \label{fig:v10_performance}
    \end{figure}

    YOLOv10は，画像の埋め込み表現$z$を獲得する写像$f(\cdot ; \theta)$（式\ref{eq:f}）とそこから物体検出用の矩形領域抽出とクラス分類に対応する出力$y$を獲得する写像$g(\cdot ; \phi)$（式\ref{eq:g}）で構成される．

    \begin{equation}
        \label{eq:f}
        \begin{gathered}
            z = f(X; \theta)
            \\ z \in \mathbb{R}^d, \quad X \in \mathbb{R}^{W \times H \times 3}
        \end{gathered}
    \end{equation}
    \begin{equation}
        \label{eq:g}
        \begin{gathered}
            y = g(z; \phi)
            \\ y \in \mathbb{R}^{n \times \left(n_c + 5\right)}
        \end{gathered}
    \end{equation}
    ここで$d$は埋め込み表現の次元数，$W$と$H$は入力画像のピクセル幅と高さ，$n$は出力されるBounding-Boxの個数，$n_c$はクラス分類において事前に準備するクラス数である．また$\theta, \phi$は学習パラメータであり，学習ステップで最適化される．
    \par
    式\ref{eq:g}における$n_c + 5$は，Boundng-Boxの$\left[x, y, w, h\right]$に加え，$[0,1]$のConfidence-Scoreと条件付きクラス確率を表している．このConfidence-Scoreとは物体らしさを表し，各クラスに属する確率は，この物体らしさと条件付きクラス確率の積で与えられる．例えばクラスの候補に犬と猫の二つを準備し（$n_c=2$），Confidence-Scoreが$0.8$，条件付きクラス確率がそれぞれ$0.8, 0.2$となった場合は，犬である確率が$0.64$，猫である確率が$0.16$となり，その物体が犬である可能性が高い，という解釈ができる．
    \par
    またYOLOv10では，Confidence-Scoreの閾値処理を行う．すなわち，閾値$\sigma_{conf}$を定め，前述のクラス確率の最大値が$\sigma_{conf}$以下であるものを出力しない．この処理により，本来は物体ではないのに物体であると判断したもの（偽陽性という）が出力される可能性を抑えることができる．ただし閾値を大きくした場合には，本来は物体であるのに検出をしない（偽陰性という）可能性が大きくなってしまうことに注意しなければならない．
    \par
    最後にYOLOv10の学習方法について述べる．一般的に学習パラメータ数の大きいニューラルネットワークや学習データが高価である場合には，図\ref{fig:PTandFT}のようにPre-TrainingとFine-Tuningという２つのステップに分けて学習が行われる．大規模なデータセットでモデルを学習させた後（Pre-Training），その学習されたパラメターを初期値として小規模なデータセットでさらに学習パラメータを調整させる（Fine-Tuning）\cite{radford2018improving}．例えば物体検出用のモデルを構築する際に，データが安価に手に入る画像分類でPre-Trainingさせた後，物体検出用のデータセットでFine-Tuningを行う．これにより，画像の処理に適した状態から物体検出用に特化させることができ，学習の安定や高精度を図れる．また物体検出用のデータセットを大量に準備する必要もなくなる．また他にも，Pre-Trainingの際に$100$クラス分類の物体検出で学習させ，Fine-Tuningで特殊な対象$1$クラス分類の物体検出を学習させることもある．Fine-Tuningでは，埋め込み表現を得る$f(\cdot ; \theta)$の部分のみを引き継ぎ，$g(\cdot; \phi)$の部分は目的のタスク用に新しく学習し直すのが一般的である．

    \begin{figure}[t]
        \centering    
        \includegraphics[width=\textwidth]{fig/PTandFT.pdf}
        \caption{Pre-TrainingとFine-Tuning}
        \label{fig:PTandFT}
    \end{figure}
    
    \subsection{SORTによるReID}
    SORT（Simple Online Realtime Tracking）は，YOLOなどの物体検出によって得られたBonding-Boxの時系列データを入力とし，これらBounding-BoxにIDを振りながら各個体の軌跡を推定する，最も基礎的な手法である．このアルゴリズムは時系列データを処理するKalman Filterと時刻間の対応付けを行うHungarian Algorithmで構成される．まずはこれらの詳細を説明する．

        \subsubsection{Kalman Filter}
        Kalman Filterとは，センサーなどから得られた時系列データからシステム内部の状態を推定するための最適化アルゴリズムである．ここでは時系列データである観測変数を$\bm{y}_1, \bm{y}_2, \dots, \bm{y}_t$，システム内部の状態変数を$\bm{x}_1, \bm{x}_2, \dots, \bm{x}_t$と表記する．Kalman Filterでは状態変数$\bm{x}_t$を推定するために，その確率分布を考える．すなわち，観測系列$\bm{y}_1, \bm{y}_2, \dots, \bm{y}_t$が得られたときの状態変数$\bm{x}_t$の事後分布$p(\bm{x}_t \left| \bm{y}_1, \bm{y}_2, \dots, \bm{y}_t \right.)$を計算する．
        \par
        ベイズの定理から，所望の事後確率は
        \begin{equation}
            \label{eq:filtering1}
            p(\left. \bm{x}_t \right| \bm{y}_1,..., \bm{y}_t ) = \frac{p(\left. \bm{y}_t \right| \bm{y}_1,..., \bm{y}_{t-1}, \bm{x}_t) p(\left.\bm{x}_t\right| \bm{y}_1,..., \bm{y}_{t-1})}{p(\left.\bm{y}_t\right| \bm{y}_1,..., \bm{y}_{t-1})}
        \end{equation}
        と変形できる．また右辺の分子後半部$p(\left.\bm{x}_t\right| \bm{y}_1,..., \bm{y}_{t-1})$は条件付き確率の性質から，
        \begin{equation}
            \label{eq:prediction1}
            \begin{aligned}
                p(\left.\bm{x}_t\right| \bm{y}_1,..., \bm{y}_{t-1}) &= \int p(\left.\bm{x}_t, \bm{x}_{t-1}\right| \bm{y}_1,..., \bm{y}_{t-1}) d\bm{x}_{t-1}
                \\ &= \int p(\left.\bm{x}_t\right|\bm{x}_{t-1}, \bm{y}_1,..., \bm{y}_{t-1}) p(\left.\bm{x}_{t-1}\right| \bm{y}_1,..., \bm{y}_{t-1}) d\bm{x}_{t-1}
            \end{aligned}        
        \end{equation}
        と変形できる．
        \par
        式\ref{eq:filtering1},\ref{eq:prediction1}から，$p(\bm{x}_0\left|\bm{y}_0\right.) = p(\bm{x}_0)$が与えられれば全ての時刻$t=1,2,\dots,t$における$p(\bm{x}_t\left|\bm{y}_1,\dots,\bm{y}_t\right.)$が理論上は計算できる．しかしながら式\ref{eq:filtering1}における右辺の分母や式\ref{eq:prediction1}における右辺には積分が含まれるため，現実には計算できない．そのためKalman Filterでは一般的に，式\ref{eq:linear_setting}に見られる線形性及びマルコフ性をシステムに仮定している（この問題設定におけるKalman Filterを特別に一般線形Kalman Filterと呼ぶこともある）．
        \begin{equation}
            \label{eq:linear_setting}
            \begin{aligned}
                \bm{x}_{t+1} &= F_t \bm{x}_t + \bm{v}_t, \quad \bm{v}_t \sim \mathcal{N}(\bm{0}, Q_t)
                \\ \bm{y}_t &= H_t \bm{x}_t + G_t \bm{u}_t + \bm{w}_t, \quad \bm{w}_t \sim \mathcal{N}(\bm{0}, R_t)
            \end{aligned}        
        \end{equation}
        上の式は状態遷移式，下の式は観測方程式と呼ばれる．ここで$F_t$は遷移行列と呼ばれる状態変数の時間遷移を，$H_t$は観測行列と呼ばれる観測変数との対応を表す行列である．また$\bm{v}_t$はシステムノイズ，$\bm{w}_t$は観測ノイズと呼ばれ，正規性を持ったホワイトノイズである．また$\bm{u}_t$はこちら側が制御する入力変数であり，ここでは後述の問題に対応するために観測方程式に加えている．$G_t$はその入力変数が観測変数に与える影響を表す行列である．
        \par
        式\ref{eq:linear_setting}より，明らかに状態変数$\bm{x}_t$と観測変数$\bm{y}_t$はマルコフ性を持っているため，式\ref{eq:filtering1}及び式\ref{eq:prediction1}は，
        \begin{equation}
            \label{eq:filtering2}
            \begin{aligned}
                p(\left. \bm{x}_t \right| \bm{y}_1,..., \bm{y}_t ) &= \frac{p(\left. \bm{y}_t \right| \bm{x}_t) p(\left.\bm{x}_t\right| \bm{y}_1,..., \bm{y}_{t-1})}{p(\left.\bm{y}_t\right| \bm{y}_1,..., \bm{y}_{t-1})}
            \end{aligned}
        \end{equation}
        \begin{equation}
            \label{eq:prediction2}
            \begin{aligned}
                p(\left.\bm{x}_t\right| \bm{y}_1,..., \bm{y}_{t-1}) = \int p(\left.\bm{x}_t\right|\bm{x}_{t-1}) p(\left.\bm{x}_{t-1}\right| \bm{y}_1,..., \bm{y}_{t-1}) d\bm{x}_{t-1}
            \end{aligned}
        \end{equation}
        と書き換えられる．
        \par
        また式\ref{eq:linear_setting}より，$\bm{x}_t$及び$\bm{y}_t$は$\bm{x}_{t-1}$が正規分布に従えば，線形な式であるためにこれらもまた正規分布に従うことが分かる．すなわち$p(\bm{x}_0)$に正規分布を仮定すれば，全ての$t$で状態変数$\bm{x}_t$と観測変数$\bm{y}_t$は正規分布に従う．よって，式\ref{eq:filtering2}と式\ref{eq:prediction2}は式\ref{eq:normal_format}のように表すことができ，
        \begin{equation}
            \label{eq:normal_format}
            \begin{aligned}
                p(\left. \bm{x}_t \right| \bm{y}_1,..., \bm{y}_t ) &= \mathcal{N}(\bm{\mu}_{t|t}, \Sigma_{t|t})
                \\ p(\left.\bm{x}_t\right| \bm{y}_1,..., \bm{y}_{t-1}) &= \mathcal{N}(\bm{\mu}_{t|t-1}, \Sigma_{t|t-1})
            \end{aligned}
        \end{equation}
        以下のように状態遷移式及び観測方程式上の行列で表現でき，計算可能となる．
        \begin{equation}
            \begin{aligned}
                \bm{\mu}_{t|t-1} &= F_{t-1} \bm{\mu}_{t-1|t-1}
                \\\Sigma_{t|t-1} &= F_{t-1} \Sigma_{t-1|t-1} F_{t-1}^{\top} + Q_{t-1}
                \\\bm{\mu}_{t|t} &= \Sigma_{t|t} \left( H_t R_t^{-1} \bm{y}_t + \Sigma_{t|t-1}^{-1} \bm{\mu}_{t|t-1} \right)
                \\\Sigma_{t|t} &= \left( H_t R_t^{-1} H_t^{\top} + \Sigma_{t|t-1}^{-1}\right)^{-1}
            \end{aligned}                    
        \end{equation}

        またKalman Filterでは，事後確率が最大な点を推定値とする．すなわち観測系列$\bm{y}_1,\bm{y}_2,\dots,\bm{y}_t$が得られたときの最適状態変数推定値$\hat{\bm{x}}_{t|t}$は，
        \begin{equation}
            \begin{aligned}
                \hat{\bm{x}}_{t|t} &= \underset{\bm{x}_t \in \mathbb{R}^{n}}{\text{argmax}}\ p(\left. \bm{x}_t \right| \bm{y}_1,..., \bm{y}_t )
                \\ &= \bm{\mu}_{t|t}
            \end{aligned}
        \end{equation}
        で与えられる．ここで$n$は状態変数の次元数である．

        \subsubsection{Hungarian Algorithm}
        後回し！！！

        \subsubsection{SORTのアルゴリズム}
        ここからは，SORTの具体的な処理の流れを説明する．SORTでは，YOLOなどの物体検出によって得られたBounding-Boxの情報$\left[x, y, w, h\right]$を観測変数$\bm{o}_t$として，各物体の状態変数$\bm{s}_t$（式\ref{eq:sort_state}参照）の推定を行う．しかし，時刻$t$の画像の中には複数の物体が存在しうるため，どのBounding-Boxが時刻$t-1$まで追跡してきた物体のいずれかと同一であるかは分からない．そこで用いられるのがHungarian Algorithmによる対応付けである．これにより，時刻$t-1$まで追跡してきた個体と同一であるBounding-Boxにはその個体のIDが振られ，Kalman Filterの観測変数として利用される（図\ref{fig:sort}参照）．

        \begin{figure}[t]
            \centering
            \includegraphics[width=\textwidth]{fig/sort.pdf}
            \caption{時刻$t=4$におけるSORTの処理の概略図}
            \small
            SORTではBounding-Boxを観測変数として状態変数の推定を行う．このときに複数のBounding-Boxを同一個体へ割り当てるために対応付けを行う．図のように，対応付けは物体検出によって得たBouning-BoxとKalman Filterによる予測位置間で行う．図の例では，赤色と緑色の物体は更新が行われている．またどの予測位置とも対応づかなかったものは新しい個体として認識される（黄色）．
            \label{fig:sort}
        \end{figure}

        アルゴリズム\ref{alg:sort}に時刻$t$におけるSORTの処理を示す．（閾値の話からスタート！！）

        \begin{algorithm}[t]
            \caption{SORT}
            \label{alg:sort}
            \begin{algorithmic}[1]
                \REQUIRE $\mathcal{T}_{t-1} = \left\{ \left. T^{(i)}\right| i \in \mathcal{I}_{t-1}\right\} , \mathcal{B}_t = \left\{\left. B^{(j)} \in \mathbb{R}^{4}\right| j \in \left\{1,2,\dots,n\right\}\right\},\sigma_a$ 
                \ENSURE $\mathcal{T}_t = \left\{ \left. T^{(i)}\right| i \in \mathcal{I}_{t} \right\}$
                \STATE $\textbf{Initialize: } \mathcal{P}_t = \emptyset,\ \mathcal{T}_t = \emptyset$
                \FOR {$T^{(i)} \in \mathcal{T}_{t-1}$}
                    \STATE $\hat{\bm{s}}_{t-1}^{(i)} = \text{GET}(T^{(i)},\hat{\bm{s}}_{t-1}^{(i)})$
                    \STATE $\mathcal{P}_t \leftarrow \mathcal{P}_t \cup kalman\_predict(\hat{\bm{s}}_{t-1}^{(i)})$
                \ENDFOR
                \STATE $M = hungarian\_matching(\mathcal{P}_t, \mathcal{B}_t)$
                \FOR {$(i, j) \in M$}
                    \STATE $B^{(j)} = \text{GET}(\mathcal{B}_t, B^{(j)})$
                    \STATE $\hat{\bm{s}}_t^{(i)} = kalman\_filtering(B^{(j)})$
                    \STATE $T^{(i)} \leftarrow T^{(i)} \cup \hat{\bm{s}}_t^{(i)}$
                    \STATE $\mathcal{T}_t \leftarrow \mathcal{T}_t \cup T^{(i)}$
                \ENDFOR
                \STATE $\mathcal{T}_t \leftarrow active\_tracks(\mathcal{T}_{t-1} / \mathcal{T}_t, \sigma_a)$
                \RETURN $\mathcal{T}_t$
            \end{algorithmic}
        \end{algorithm}

    \subsection{既存手法適用における問題点}


\section{提案手法の設計思想}

\section{SliceKalmanFilterの設計}

\section{スライス３次元画像におけるReID}

    \subsection{SliceKalmanFilter予測によるマッチング}

    \subsection{SORT+DepthSORTによるマッチング}