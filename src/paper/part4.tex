\thispagestyle{fancy2}

提案手法の構成は大きく，(1)物体検出，(2)ReIDによる観測系列の取得，(3)カルマンフィルタによる状態推定に分けられる．そこで本章ではまず，検証用データ（4.1節）を用いて各パートごとに性能評価を行う．そして次に，これら三つのパートを組み合わせた提案手法全体で評価を行い（4.2節），各パートごとに設定されているハイパーパラメータや補助的なアルゴリズムの効果・相互作用を検討する（4.3節）．そして最後に，問題設定の背景であったプロトプラスト化した細胞に対して提案手法を適用し，性能評価および考察・検討を行う（4.4節）．

\section{検証用データの詳細}

この章では，本問題設定における入力，
\begin{equation}
    \label{eq:input_remind}
    \begin{aligned}
        \mathcal{X}_t &\equiv \left\{ \left.X^{(t,s)}\right| s \in \left\{1,2,\dots,n_s\right\} \right\}
        \\ X^{(t,s)} &\in \mathbb{R}^{W \times H \times 3}
    \end{aligned}    
\end{equation}
の検証用データ（図\ref{fig:slicing}参照）の作成方法を記す．また検証用データはプログラムで作成するため，時刻$t$は連続時刻ではなく離散時刻として扱わなければならない．よってまずは第二部で述べた問題設定の離散化を述べた後，検証用データの作成手順を記す．

    \subsection{問題設定の時刻離散化}
    ある一つの球体の状態変数$\bm{s}(t)$は，
    \begin{equation}
        \label{eq:state_vector_remind}
        \bm{s}(t) = \left[x(t), \dot{x}(t), y(t), \dot{y}(t), z(t), \dot{z}(t), r(t)\right]^{\top}
    \end{equation}
    で与えられていた（これは式\ref{eq:state_vector}の再掲である）．しかしながら計算機では離散化が必要であるため，これを離散化して
    \begin{equation}
        \label{eq:discreated_state_vector}
        \bm{s}_t = \left[x_t, \dot{x}_t, y_t, \dot{y}_t, z_t, \dot{z}_t, r_t\right]
    \end{equation}
    と表す．またこれを用いて時間差$dt$による時間遷移は，
    \begin{equation}
        \label{eq:discreated_transition}
        \begin{aligned}
            x_{t+1} &= x_t + \dot{x}_t dt + \frac{1}{2} a_x dt^2
            \\ \dot{x}_{t+1} &= \dot{x}_t + a_x dt
            \\ a_x & \sim \mathcal{N}(0, A_x)
        \end{aligned}
    \end{equation}
    で表される．ここで$a_x$は離散化された時刻$t$における加速度であり，ホワイトノイズとしている．またそのホワイトノイズには平均$0$，分散$A_x$の正規確率変数を用いている．ここでは$x$についてのみの時間遷移を示したが，$y, z$についても同様な時間遷移を持つ．

    またある連続時刻$t + \tau(s)$に撮影されたスライス画像$s$に映る，ある球体のスライス円の領域$R$は式\ref{eq:...}に見られるように，その球体の時刻$t + \tau(s)$における位置$x(t + \tau(s)), y(t + \tau(s)), z(t + \tau(s))$および半径$r(t + \tau(s))$から計算することができた．しかしながら離散化を行う場合，われわれは離散時刻における位置や速度しか知ることができない．よって時刻$t + \tau(s)$における離散位置$x_{t + \tau{s}}$は，
    \begin{equation}
        \label{eq:discreated_position_on_slice}
        x_{t + \tau{s}} = x_t + \dot{x}_t \frac{\tau(s)}{dt} + \frac{1}{2} a_x \left(\frac{\tau(s)}{dt}\right)^2
    \end{equation}
    と表され（$y,z$も同様），スライス$s$上での見かけの半径$r_{\text{app}}$は，
    \begin{equation}
        \label{eq:discreated_appearant_radius}
        r_{\text{app}} = \left\{
            \begin{aligned}
               & \sqrt{r_t^2 - \left(z_{t + \tau(s)} - z_s\right)^2}, \quad&& \textbf{if }r_t \geq \left|z_{t + \tau(s)} - z_s\right|
               \\ & \text{None}, && \textbf{else}
            \end{aligned}
        \right.
    \end{equation}
    で表される．以上より上述のスライス円の領域$R$は，
    \begin{equation}
        \label{eq:discreated_slice_circle_region}
        R = \left\{(x, y) \mid 
        \begin{aligned}
            & (x - x_{t + \tau(s)})^2 + (y - y_{t + \tau(s)})^2 \leq r_t^2
            \\ & (x, y) \in [0, \ell]^2
            \\ & r_t > \left| z_{t + \tau(s)} - z_s \right|
        \end{aligned} 
        \right\}
    \end{equation}
    で表される．ただし$z_s$はあるスライス$s$の高さである．

    \subsection{検証用データの作成手順}

    検証データの作成では，存在する物体数$n_b$，単一時刻におけるスライス数$n_s$，ある単一スライスの画像が取得される枚数合計を$n_f$，対象とする空間$\Omega = [0, \ell]^3$およびその大きさを決めるパラメータ$\ell$，あるスライスの画像が一度取得されてからもう一度取得されるまでにかかる時間を$dt$とする．またスライス$0$が取得されてからスライス$s$が取得されるまでにかかる時間を$\tau(s)$とする．以下に作成手順を示す．

    \begin{description}
        \item[手順1] 物体数$n_b$個分の状態変数ベクトル（式\ref{eq:discreated_state_vector}）を初期化する．また時刻は$t=0$とする．
        \item[手順2] 式\ref{eq:discreated_transition}に従って各物体の状態変数を更新し，$t \gets t + 1$とする．
        \item[手順3] 各スライス$s=1,2,\dots,n_s$に対して，式\ref{eq:discreated_position_on_slice}から式\ref{eq:discreated_slice_circle_region}に従って画像$X^{(t,s)}$を生成し，\textgt{手順2}に戻る．
    \end{description}

    また\textgt{手順1}における初期化では，位置については$\Omega$内から，速度は絶対値$v_{\text{range}}$をハイパーパラメータとして$[-v_{\text{range}}, v_{\text{range}}]$から，半径は最大値$r_{\text{max}}$をハイパーパラメータとして$[0, r_{\text{max}}]$からランダムに与える．

    以降の実験では，物体数は$n_b = 20$，空間の大きさは$\ell = 100.0$，共焦点画像一枚にかかる時間を$1$とし，他のハイパーパラメータは実験ごとに設定する．

\section{提案手法の各パートごとの性能評価}

    \subsection{物体検出手法YOLOの評価}

    物体検出手法として6つのサイズのYOLOv10（B/N/S/M/L/X）の評価を行う．本論文ではリアルタイム物体追跡を行うための一部分としての物体検出を行うため，全体的な評価の後に偽陽性（FP）や偽陰性（FN）の個数およびハイパーパラメータの変動によるそれらの変化に着目した評価を行う．

    YOLOv10は，すでにUltralytics社に公開されているPre-Training済みのモデルを利用し，検証用データでFine-Tuningを行う．この際に使用した訓練データの詳細を表\ref{tab:fine_tuning}に示す．また今回は全ての層の重みを更新する．本問題設定では白色の円領域のみを検出すればよいため，クラス数は$n_c = 1$としている．その他ハイパーパラメータはYOLOv10の論文\cite{wang2024yolov10}と同様にしている．

    \begin{table}[t]
        \centering
        \caption[YOLOv10のFine-Tuningに用いたデータセット]{YOLOv10のFine-Tuningに用いたデータセット}
        \label{tab:fine_tuning}
        \begin{tabular}{|l||cccc|}
            \hline parameters & $n_s$ & $n_f$ & $r_{\text{max}}$ & $v_{\text{range}}$ 
            \\ \hline values & $101$ & $101$ & $10$ & $0.1$ \\\hline
        \end{tabular}
    \end{table}

    評価指標には，物体検出でしばしば使用されるAP（Average Precision）を使用する（一般的には各クラスごとのAPを平均化したmAPを用いるが，今回は$n_c=1$のためAPとして記載している）．これを説明するために，まず物体検出における真陽性（TP），偽陽性（FP），真陰性（TN）および偽陰性（FN）について説明する．ただし以下では，$n_c = 1$を前提として説明を行う．
    
    画像分類や一般的な検査では，検査結果と対象とされた画像および人物などが対応づいている．しかしながら物体検出では物体領域も推論対象であるため，どのBounding-Boxがどの正解データと対応づいているかを事前に決められない．そこでIoU（Intersection over Union）が閾値以上のものを対応づいた推論結果および正解データとしてみなす．

    よって各推論結果について，IoUが閾値以上になる正解データが一つでもあればTP，なければFPとなる．また各正解データについて，IoUが閾値以上になる推論結果が一つでもあればTP，なければTNとなる．また物体ではない領域は無数に定義できてしまうため，物体検出におけるFNは定義されない．

    これらを用いて，Precision $p$およびRecall $r$という評価指標は，
    \begin{equation}
        \label{eq:object_detection_metrics}
        \begin{aligned}
            p &= \frac{TP}{TP + FP}
            \\r &= \frac{TP}{TP + FN}
        \end{aligned}
    \end{equation}
    と表される．すなわち，Precisionは陽性と判断したBounding-Boxのうち本当に物体だったものの割合，Recallは物体だったもののうち検出に成功したBounding-Boxの割合をそれぞれ示している．

    さらに，ある実験設定のハイパーパラメータ集合を$\sigma$とすると，ある実験設定におけるPrecisionとRecallはそれぞれ$p(\sigma), r(\sigma)$と媒介変数表示することができる．よってあるRecallの値$r(\sigma)$と取るときのPrecisionの値を$p(r)$と表すことができる．これを用いて前述のAPは，
    \begin{equation}
        \label{eq:averate_precision}
        \begin{aligned}
            \text{AP} &= \frac{1}{11} \sum_{r \in \left\{0, 0.1, \dots, 1.0\right\}} \rho(r)
            \\ &= \frac{1}{11} \left(\rho(0) + \rho(0.1) + \rho(0.2) + \cdots + \rho(1.0)\right),
            \\ &\textbf{where }\rho(r) = \max_{0 \leq r' \leq r} p(r')
        \end{aligned}
    \end{equation}
    と表される．以降の節では，このAPと説明途中に現れたFPやFNを対象として議論を行う．

    図\ref{fig:metrics_yolo}に，代表値としてYOLOv10-Sで検出を行った際の結果を示す．検証用データでは，ほとんどのConfidence閾値でPrecision，Recallがともに1に近い値になっている．またPrecisionの曲線のみに着目すると，閾値にはほとんど関係ないことが分かる．一方でRecallの曲線に着目するとある閾値以上で検出できない対象が生じてしまうことが分かるため，この結果からは必要以上に閾値を高くしなければどんな値でも大きな問題がないことを示している．

    右図には，FPおよびFNが生じた画像の検出結果を示している．誤検出であるFPは，同じ物体に複数個の検出結果が現れていることで生じている．これはYOLOv10に冗長な検出結果を決定的に除去するNon-Maximum Supression（NMS）処理が入っていないためである．反対に考えれば，NMS処理を行うことでこれらのFPは抑えることができる．またNMSは検出結果が多い場合にはその処理時間が問題視されるが，YOLOv10はNMS処理無しで検出結果を抑えることができる構造になっているため，処理時間も問題になりづらい．

    一方見逃しであるFNは，極端に対象物体が小さい場合や，対象の大部分が画像範囲内からはずれていることで生じていることがわかる．検出タスクのみで考えればこれは問題になりうるかもしれないが，前述の通り本問題設定では物体検出はReIDの入力のために行われる．そのためこのFNの影響は後の4.3節で議論する．

    \begin{figure}[t]
        \centering
        \includegraphics[width=\linewidth]{fig/yolov10-s_result.pdf}
        \caption[YOLOv10-Sの検証用データに対する検出結果]{YOLOv10-Sの検証用データに対する検出結果}
        \label{fig:metrics_yolo}
    \end{figure}

    また，各モデルサイズN,S,M,B,L,Xごとの精度mAPと推論速度の関係を図\ref{fig:map_runtime}に示す．評価指標mAPの最大値は1であるため，図から分かる通り検証用データのような対象であれば，いずれのモデルを用いても精度には影響はない．そのため本問題設定では，もっとも推論速度の小さいNモデルを採用した方が良い，と結論付けられる．この際，一枚の画像の物体検出にかかる推論時間は，少なくとも共焦点顕微鏡が一枚の画像を取得するよりも短くなければいけない．

    \begin{figure}[t]
        \centering
        \includegraphics[width=\linewidth]{fig/map_runtime.pdf}
        \caption[YOLOv10の検出精度と推論速度]{YOLOv10の検出精度と推論速度}
        \label{fig:map_runtime}
    \end{figure}

    \subsection{ReID手法の評価・選択}

    

    \subsection{SliceKalmanFilterの性能評価}

\section{パート同士の相互影響の検討・考察}

\section{プロトプラスト化した細胞への適用}