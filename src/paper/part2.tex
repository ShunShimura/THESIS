この章では，個性付き１細胞取得システムを達成するためのAIシステムの概要説明，およびAIが解くタスクの定式化を行う．

\section{AIシステムの概要}
上述の通り，本プロジェクトでは細胞の個性として遊離前の細胞の位置情報を設定している．その位置情報を保持するために，AIを用いてリアルタイム細胞追跡を行う．これにより得られる効果は以下の２つである．
\begin{itemize}
    \item 各細胞の現在の位置，及び一定時間後の位置を予測することができる．
    \item 各細胞に対して，遊離する前のそれぞれの位置を保持することができる．
\end{itemize}
また，AIに入力するデータは，共焦点顕微鏡から得られる画像データである．ここで共焦点顕微鏡とは，焦点と共役する位置にピンホールを置くことで焦点外で発生した光を排除し，対象物体の光学断面像（以降スライスと呼ぶ）を得ることができる顕微鏡である（図\ref{fig:confocal-microscope}参照）．
\par
本タスクはリアルタイム細胞追跡を行うため，時刻$t$の画像データが入るたびに処理を行うオンライン処理であることに注意されたい．このとき，時間方向のフレーム長さ$n_f$と時間間隔$dt$はハイパーパラメータである．
\par
以降では，時刻$t$におけるAIシステムの入力，出力について詳細を述べたあと，タスクを一般化し，本プロジェクトに適用するための課題点を説明する．

\section{共焦点顕微鏡から得られる画像データ}
前述の通り共焦点顕微鏡とは，焦点外で発生した光を排除し，対象物体のスライス像を得ることができる顕微鏡である．例えば図\ref{fig:confocal-microscope}では，サンプル上で緑色の光路が反射している高さのスライス像を取得する際の光路の一例を示している．右図に示すように，赤色の光路が反射している高さの光は，ピンホール１より手前で集光するために検出器に入る前に除去される．

\begin{figure}[h]
    \includegraphics[width=\linewidth]{fig/fig1.pdf}
    \centering
    \caption{共焦点顕微鏡の概略図}
    \vspace{-5pt}
    {\small 左の図では，緑色の光路が反射しているサンプルの高さであれば光を集光できている．一方右の図では，高さが合わず集光ができていない，言い換えれば赤い色の光路が反射している高さの情報を除去できていることが分かる．}
    \label{fig:confocal-microscope}
\end{figure}

そして水平方向に走査させることで，ある高さにおける２次元画像を取得することができる．また，この高さを動的に変更することができることが共焦点顕微鏡の強みである．これにより，サンプルの３次元情報を，複数のスライスという形で捉えることが可能となる．このとき，スライスの枚数$n_s$とその間隔$dz$はハイパーパラメータである．
\par
以上の説明により，時刻$t$におけるAIシステムの入力は$n_s$枚の２次元画像データである．ただし，各スライスが取得された時刻が異なることに注意されたい．ここで，ある時刻$t$におけるある高さ$z$のスライス$s_{t,z} \in \mathcal{S}$を入力して取得された時刻$t_{t,z} \in \mathcal{T}$を出力する写像$f:\mathcal{S} \rightarrow \mathcal{T}$を考える．このとき$f$は，

\begin{equation}
    f(s_{t,z}) = t + \frac{s}{n_s} dt
    \label{slice-time}
\end{equation}

と表せられる．ここで$n_s$はスライス数，$dt$は時間間隔である．

\section{細胞の位置予測と遊離前位置の特定}
次に，AIシステムの出力データについて述べる．時刻$t$における出力データは，以下の２つである．
\begin{itemize}
    \item 時刻$t+1$の各細胞に対する予測位置$\left[x, y, z, r\right]$
    \item 各細胞に対する，遊離直後の推定位置$\left[x, y, z, r\right]$
\end{itemize}
ここで，$\left(x,y,z\right)$は細胞を球とみなしたときの中心位置，$r$は半径である．以降ではそれぞれについて詳細に述べる．
\subsection{時刻$t+1$の予測}
本プロジェクトでは，マイクロロボットツールを用いて細胞の収集を行う．しかしながら手動で操作する場合では，非常に効率が悪くなる．理由としては主に２つある．１つ目は，微調整に時間がかかるためである．水平方向へはもちろんのことだが，特に鉛直方向の調整は容易には行えない．なぜならば，マイクロロボットツールの先端は共焦点顕微鏡には映らず，スライスではない通常の明視野顕微鏡で位置合わせを行わなければならないためである．そのため，対象の細胞がどの高さにあるかを特定できず，トライアンドエラーで高さを調整しなければならない．２つ目は，収集経路に無駄が生じてしまうためである．本プロジェクトの目的は遺伝子発現パターンと再生力の関係を探ることであるため，サンプル数はできる限り多いほうがよい．そのため，工夫をせずに収集を行うと，多大な時間を要してしまう．
\par
よってAIシステムでは，各細胞の時刻$t+1$の位置及び速度を予測し，それらの情報をもとにロボットへの指示をAIシステムによって行う．本研究の範囲外ではあるが，これらの情報を用いることで最適経路の計算が可能になる．
\par
以上より，時刻$t$における時刻$t+1$の予測位置の出力は，式\eqref{output1}のように表せられる．

\begin{equation}
    \label{output1}
    \begin{aligned}
        S_t &= \left\{\hat{\bm{s}}_1^{(t+1)}, \hat{\bm{s}}_2^{(t+1)}, ..., \hat{\bm{s}}_n^{(t+1)}\right\}
        \\ \hat{\bm{s}}_i^{(t+1)} &= \left[x, \dot{x}, y, \dot{y}, z, \dot{z}, r\right] \hspace{10pt} i = 1,2,...,n
    \end{aligned}
\end{equation}

ここで，$n$は時刻$t$で追跡している細胞の個数，$\hat{\bm{s}}_i^{(t+1)}$は，各細胞$i$の時刻$t+1$の予測位置，$(x,y,z)$は細胞を球とみなしたときの中心位置，$(\dot{x},\dot{y}, \dot{z})$は中心位置の速度，$r$は半径である．

\subsection{遊離直後の位置推定}
本プロジェクトのシステムでは，細胞の遊離前位置の保持を目的としていた．しかしAIシステムでは，遊離前の位置ではなく，遊離直後の位置の保持を行う．なぜならば，遊離前の位置特定の3Dセグメンテーション処理に時間がかかるためである．ここでセグメンテーションとは，画像１ピクセルに対してラベルを割り当てる処理のことをいう．反対に，遊離したあとの細胞を追跡するには，セグメンテーションを行う必要はなく，後述の物体検出処理で十分である．また，物体検出処理であれば高速で行うことができる．そのためAIシステムでは，遊離直後の位置から追跡を開始し，事後に3Dセグメンテーションと追跡処理の対応付けを行う．
\par
時刻$t$における各細胞の遊離直後位置の出力は，2.3.1と同様に以下のように表せられる．

\begin{equation}
    \label{output1}
    \begin{aligned}
        S_t^{\textrm{init}} &= \left\{\hat{\bm{s}}_1^{\textrm{init}}, \hat{\bm{s}}_2^{\textrm{init}}, ..., \hat{\bm{s}}_n^{\textrm{init}}\right\}
        \\ \hat{\bm{s}}_i^{\textrm{init}} &= \left[x, \dot{x}, y, \dot{y}, z, \dot{z}, r\right] \hspace{10pt} i = 1,2,...,n
    \end{aligned}
\end{equation}

ここで，$n$は時刻$t$で追跡している細胞の個数，$\hat{\bm{s}}_i^{\textrm{init}}$は，各細胞$i$の追跡が開始した時刻における推定位置，$(x,y,z)$は細胞を球とみなしたときの中心位置，$(\dot{x},\dot{y}, \dot{z})$は中心位置の速度，$r$は半径である．

\section{課題点と問題の一般化}